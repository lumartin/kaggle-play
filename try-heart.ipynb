{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart disease dataset from kaggle\n",
    "\n",
    "We need to shuffle the data, as positive and negative examples are not mixed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "64    58    1   2       140   211    1        0      165      0      0.0   \n",
       "150   66    1   0       160   228    0        0      138      0      2.3   \n",
       "155   58    0   0       130   197    0        1      131      0      0.6   \n",
       "27    51    1   2       110   175    0        1      123      0      0.6   \n",
       "63    41    1   1       135   203    0        1      132      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "64       2   0     2       1  \n",
       "150      2   0     1       1  \n",
       "155      1   0     2       1  \n",
       "27       2   0     2       1  \n",
       "63       1   0     1       1  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "\n",
    "#data = pd.read_csv(\"./data/heart.csv\", usecols=[0,1,2,3,4,5,6,7,8,9,10,11,12]) \n",
    "#target = pd.read_csv(\"./data/heart.csv\", usecols=[13]) \n",
    "\n",
    "data = pd.read_csv(\"./data/heart.csv\")\n",
    "data = data.sample(frac=1)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>211</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "64    58    1   2       140   211    1        0      165      0      0.0   \n",
       "150   66    1   0       160   228    0        0      138      0      2.3   \n",
       "155   58    0   0       130   197    0        1      131      0      0.6   \n",
       "27    51    1   2       110   175    0        1      123      0      0.6   \n",
       "63    41    1   1       135   203    0        1      132      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "64       2   0     2  \n",
       "150      2   0     1  \n",
       "155      1   0     2  \n",
       "27       2   0     2  \n",
       "63       1   0     1  "
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X = data.iloc[:, :13]\n",
    "target_X = data.iloc[:, 13]\n",
    "\n",
    "data_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X.values #convert to numpy darray\n",
    "target_X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13)\n"
     ]
    }
   ],
   "source": [
    "print(data_X.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as k\n",
    "\n",
    "X = k.utils.normalize(data_X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(223, 13) (223,)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[80:]\n",
    "X_test = X[-223:]\n",
    "\n",
    "Y_train = target_X[80:]\n",
    "Y_test = target_X[-223:]\n",
    "\n",
    "print(X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(13,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy' , optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 223 samples, validate on 223 samples\n",
      "Epoch 1/800\n",
      "223/223 [==============================] - 0s 161us/step - loss: 0.2651 - acc: 0.8700 - val_loss: 0.2475 - val_acc: 0.8879\n",
      "Epoch 2/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.2325 - acc: 0.8924 - val_loss: 0.2264 - val_acc: 0.8789\n",
      "Epoch 3/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.2293 - acc: 0.8879 - val_loss: 0.2290 - val_acc: 0.8879\n",
      "Epoch 4/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.2353 - acc: 0.8744 - val_loss: 0.2250 - val_acc: 0.8744\n",
      "Epoch 5/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.2287 - acc: 0.8789 - val_loss: 0.2187 - val_acc: 0.8789\n",
      "Epoch 6/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.2208 - acc: 0.8879 - val_loss: 0.2153 - val_acc: 0.8834\n",
      "Epoch 7/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.2184 - acc: 0.8789 - val_loss: 0.2138 - val_acc: 0.8834\n",
      "Epoch 8/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.2212 - acc: 0.8700 - val_loss: 0.2142 - val_acc: 0.8834\n",
      "Epoch 9/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.2180 - acc: 0.8834 - val_loss: 0.2123 - val_acc: 0.8834\n",
      "Epoch 10/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.2227 - acc: 0.8924 - val_loss: 0.2124 - val_acc: 0.8879\n",
      "Epoch 11/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.2392 - acc: 0.8879 - val_loss: 0.2442 - val_acc: 0.8789\n",
      "Epoch 12/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2382 - acc: 0.8924 - val_loss: 0.2300 - val_acc: 0.8700\n",
      "Epoch 13/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.2294 - acc: 0.8834 - val_loss: 0.2225 - val_acc: 0.8924\n",
      "Epoch 14/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.2225 - acc: 0.8924 - val_loss: 0.2185 - val_acc: 0.8924\n",
      "Epoch 15/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.2189 - acc: 0.8834 - val_loss: 0.2232 - val_acc: 0.8879\n",
      "Epoch 16/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2200 - acc: 0.8924 - val_loss: 0.2213 - val_acc: 0.8879\n",
      "Epoch 17/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.2364 - acc: 0.8789 - val_loss: 0.2468 - val_acc: 0.8655\n",
      "Epoch 18/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.2278 - acc: 0.8789 - val_loss: 0.2486 - val_acc: 0.8700\n",
      "Epoch 19/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.2424 - acc: 0.8700 - val_loss: 0.2521 - val_acc: 0.8565\n",
      "Epoch 20/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2253 - acc: 0.8969 - val_loss: 0.2309 - val_acc: 0.8969\n",
      "Epoch 21/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.2339 - acc: 0.8789 - val_loss: 0.2346 - val_acc: 0.8879\n",
      "Epoch 22/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2196 - acc: 0.8834 - val_loss: 0.2162 - val_acc: 0.8924\n",
      "Epoch 23/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2338 - acc: 0.8789 - val_loss: 0.2279 - val_acc: 0.8700\n",
      "Epoch 24/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2160 - acc: 0.8834 - val_loss: 0.2284 - val_acc: 0.8789\n",
      "Epoch 25/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2293 - acc: 0.8834 - val_loss: 0.2146 - val_acc: 0.8924\n",
      "Epoch 26/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2357 - acc: 0.9013 - val_loss: 0.2074 - val_acc: 0.8879\n",
      "Epoch 27/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2608 - acc: 0.8655 - val_loss: 0.2252 - val_acc: 0.8969\n",
      "Epoch 28/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2290 - acc: 0.8834 - val_loss: 0.2070 - val_acc: 0.8969\n",
      "Epoch 29/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.2151 - acc: 0.8789 - val_loss: 0.2047 - val_acc: 0.8924\n",
      "Epoch 30/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2079 - acc: 0.8924 - val_loss: 0.2055 - val_acc: 0.8924\n",
      "Epoch 31/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.2081 - acc: 0.9013 - val_loss: 0.2037 - val_acc: 0.9013\n",
      "Epoch 32/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.2064 - acc: 0.8924 - val_loss: 0.2050 - val_acc: 0.8834\n",
      "Epoch 33/800\n",
      "223/223 [==============================] - 0s 152us/step - loss: 0.2137 - acc: 0.8879 - val_loss: 0.2103 - val_acc: 0.8969\n",
      "Epoch 34/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.2104 - acc: 0.8969 - val_loss: 0.2021 - val_acc: 0.9013\n",
      "Epoch 35/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.2159 - acc: 0.8879 - val_loss: 0.2032 - val_acc: 0.8969\n",
      "Epoch 36/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.2159 - acc: 0.8924 - val_loss: 0.1997 - val_acc: 0.8834\n",
      "Epoch 37/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.2032 - acc: 0.8879 - val_loss: 0.2010 - val_acc: 0.8969\n",
      "Epoch 38/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2042 - acc: 0.8879 - val_loss: 0.1995 - val_acc: 0.9058\n",
      "Epoch 39/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.2057 - acc: 0.8969 - val_loss: 0.1986 - val_acc: 0.8969\n",
      "Epoch 40/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.2010 - acc: 0.8879 - val_loss: 0.1990 - val_acc: 0.8969\n",
      "Epoch 41/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.2069 - acc: 0.8924 - val_loss: 0.1992 - val_acc: 0.8924\n",
      "Epoch 42/800\n",
      "223/223 [==============================] - 0s 150us/step - loss: 0.1991 - acc: 0.8879 - val_loss: 0.1987 - val_acc: 0.8924\n",
      "Epoch 43/800\n",
      "223/223 [==============================] - 0s 139us/step - loss: 0.2092 - acc: 0.9013 - val_loss: 0.2006 - val_acc: 0.8969\n",
      "Epoch 44/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.2081 - acc: 0.9013 - val_loss: 0.1974 - val_acc: 0.8924\n",
      "Epoch 45/800\n",
      "223/223 [==============================] - 0s 139us/step - loss: 0.2157 - acc: 0.8834 - val_loss: 0.2003 - val_acc: 0.8969\n",
      "Epoch 46/800\n",
      "223/223 [==============================] - 0s 141us/step - loss: 0.2017 - acc: 0.9013 - val_loss: 0.1941 - val_acc: 0.8924\n",
      "Epoch 47/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.2078 - acc: 0.8924 - val_loss: 0.1935 - val_acc: 0.9058\n",
      "Epoch 48/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.2216 - acc: 0.8789 - val_loss: 0.1980 - val_acc: 0.9013\n",
      "Epoch 49/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.2127 - acc: 0.8924 - val_loss: 0.1990 - val_acc: 0.9013\n",
      "Epoch 50/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2060 - acc: 0.8879 - val_loss: 0.2145 - val_acc: 0.9013\n",
      "Epoch 51/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2153 - acc: 0.8969 - val_loss: 0.2054 - val_acc: 0.9013\n",
      "Epoch 52/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1989 - acc: 0.9013 - val_loss: 0.2009 - val_acc: 0.8924\n",
      "Epoch 53/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.2055 - acc: 0.8924 - val_loss: 0.1928 - val_acc: 0.9058\n",
      "Epoch 54/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1954 - acc: 0.9013 - val_loss: 0.1941 - val_acc: 0.8969\n",
      "Epoch 55/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2021 - acc: 0.8834 - val_loss: 0.1908 - val_acc: 0.9058\n",
      "Epoch 56/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2051 - acc: 0.8879 - val_loss: 0.1938 - val_acc: 0.9058\n",
      "Epoch 57/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.2081 - acc: 0.8834 - val_loss: 0.2007 - val_acc: 0.9058\n",
      "Epoch 58/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2002 - acc: 0.8924 - val_loss: 0.1969 - val_acc: 0.8924\n",
      "Epoch 59/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.2063 - acc: 0.8655 - val_loss: 0.1982 - val_acc: 0.9013\n",
      "Epoch 60/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2016 - acc: 0.9013 - val_loss: 0.1890 - val_acc: 0.9058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1964 - acc: 0.8969 - val_loss: 0.1887 - val_acc: 0.9103\n",
      "Epoch 62/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1900 - acc: 0.9103 - val_loss: 0.1880 - val_acc: 0.9148\n",
      "Epoch 63/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1922 - acc: 0.9013 - val_loss: 0.1865 - val_acc: 0.9103\n",
      "Epoch 64/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1935 - acc: 0.9013 - val_loss: 0.1875 - val_acc: 0.9058\n",
      "Epoch 65/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1918 - acc: 0.9058 - val_loss: 0.1867 - val_acc: 0.9058\n",
      "Epoch 66/800\n",
      "223/223 [==============================] - 0s 146us/step - loss: 0.1949 - acc: 0.9013 - val_loss: 0.1892 - val_acc: 0.9013\n",
      "Epoch 67/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1969 - acc: 0.9058 - val_loss: 0.1997 - val_acc: 0.8924\n",
      "Epoch 68/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1946 - acc: 0.9013 - val_loss: 0.1987 - val_acc: 0.9013\n",
      "Epoch 69/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.2195 - acc: 0.8924 - val_loss: 0.1850 - val_acc: 0.9058\n",
      "Epoch 70/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.2256 - acc: 0.8565 - val_loss: 0.2423 - val_acc: 0.8610\n",
      "Epoch 71/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.2330 - acc: 0.8789 - val_loss: 0.2885 - val_acc: 0.8744\n",
      "Epoch 72/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2942 - acc: 0.9148 - val_loss: 0.6462 - val_acc: 0.7803\n",
      "Epoch 73/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.4127 - acc: 0.8117 - val_loss: 0.3897 - val_acc: 0.7758\n",
      "Epoch 74/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.3972 - acc: 0.8027 - val_loss: 0.3332 - val_acc: 0.8430\n",
      "Epoch 75/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.3553 - acc: 0.8475 - val_loss: 0.2743 - val_acc: 0.8565\n",
      "Epoch 76/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.2851 - acc: 0.8700 - val_loss: 0.2598 - val_acc: 0.8789\n",
      "Epoch 77/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.2744 - acc: 0.8655 - val_loss: 0.2383 - val_acc: 0.8879\n",
      "Epoch 78/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2516 - acc: 0.8924 - val_loss: 0.2254 - val_acc: 0.9013\n",
      "Epoch 79/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.2256 - acc: 0.8924 - val_loss: 0.2111 - val_acc: 0.8969\n",
      "Epoch 80/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.2085 - acc: 0.8969 - val_loss: 0.1956 - val_acc: 0.9148\n",
      "Epoch 81/800\n",
      "223/223 [==============================] - 0s 143us/step - loss: 0.1993 - acc: 0.9148 - val_loss: 0.1914 - val_acc: 0.9193\n",
      "Epoch 82/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.1931 - acc: 0.9103 - val_loss: 0.1891 - val_acc: 0.9058\n",
      "Epoch 83/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1968 - acc: 0.8924 - val_loss: 0.1943 - val_acc: 0.9013\n",
      "Epoch 84/800\n",
      "223/223 [==============================] - 0s 143us/step - loss: 0.2007 - acc: 0.8969 - val_loss: 0.1905 - val_acc: 0.8969\n",
      "Epoch 85/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1948 - acc: 0.8969 - val_loss: 0.1850 - val_acc: 0.9148\n",
      "Epoch 86/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1884 - acc: 0.9058 - val_loss: 0.1884 - val_acc: 0.9058\n",
      "Epoch 87/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1961 - acc: 0.8969 - val_loss: 0.1857 - val_acc: 0.9058\n",
      "Epoch 88/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1931 - acc: 0.8969 - val_loss: 0.1854 - val_acc: 0.9148\n",
      "Epoch 89/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1956 - acc: 0.9148 - val_loss: 0.1862 - val_acc: 0.9103\n",
      "Epoch 90/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1951 - acc: 0.9058 - val_loss: 0.1851 - val_acc: 0.9148\n",
      "Epoch 91/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1851 - acc: 0.9148 - val_loss: 0.1873 - val_acc: 0.9103\n",
      "Epoch 92/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1835 - acc: 0.9103 - val_loss: 0.1799 - val_acc: 0.9148\n",
      "Epoch 93/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1842 - acc: 0.9103 - val_loss: 0.1825 - val_acc: 0.9058\n",
      "Epoch 94/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1872 - acc: 0.9238 - val_loss: 0.1888 - val_acc: 0.9103\n",
      "Epoch 95/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1880 - acc: 0.9058 - val_loss: 0.1801 - val_acc: 0.9103\n",
      "Epoch 96/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1896 - acc: 0.8969 - val_loss: 0.1797 - val_acc: 0.9193\n",
      "Epoch 97/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1809 - acc: 0.9148 - val_loss: 0.1787 - val_acc: 0.9238\n",
      "Epoch 98/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1828 - acc: 0.9103 - val_loss: 0.1880 - val_acc: 0.9103\n",
      "Epoch 99/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1937 - acc: 0.9058 - val_loss: 0.1826 - val_acc: 0.9238\n",
      "Epoch 100/800\n",
      "223/223 [==============================] - 0s 141us/step - loss: 0.1990 - acc: 0.9013 - val_loss: 0.1807 - val_acc: 0.9193\n",
      "Epoch 101/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2190 - acc: 0.8969 - val_loss: 0.2324 - val_acc: 0.8700\n",
      "Epoch 102/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2089 - acc: 0.8924 - val_loss: 0.2093 - val_acc: 0.9013\n",
      "Epoch 103/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1876 - acc: 0.9103 - val_loss: 0.2129 - val_acc: 0.8879\n",
      "Epoch 104/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2091 - acc: 0.8924 - val_loss: 0.1855 - val_acc: 0.9103\n",
      "Epoch 105/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1966 - acc: 0.8969 - val_loss: 0.1924 - val_acc: 0.9103\n",
      "Epoch 106/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1994 - acc: 0.8879 - val_loss: 0.1887 - val_acc: 0.9103\n",
      "Epoch 107/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1937 - acc: 0.8924 - val_loss: 0.1763 - val_acc: 0.9013\n",
      "Epoch 108/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1913 - acc: 0.9148 - val_loss: 0.2002 - val_acc: 0.8969\n",
      "Epoch 109/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2035 - acc: 0.8924 - val_loss: 0.1942 - val_acc: 0.8924\n",
      "Epoch 110/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1935 - acc: 0.9013 - val_loss: 0.2153 - val_acc: 0.8700\n",
      "Epoch 111/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.2198 - acc: 0.8700 - val_loss: 0.1779 - val_acc: 0.9193\n",
      "Epoch 112/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1981 - acc: 0.9058 - val_loss: 0.1790 - val_acc: 0.9058\n",
      "Epoch 113/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1799 - acc: 0.9148 - val_loss: 0.1739 - val_acc: 0.9148\n",
      "Epoch 114/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1910 - acc: 0.9013 - val_loss: 0.1930 - val_acc: 0.9013\n",
      "Epoch 115/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1793 - acc: 0.9148 - val_loss: 0.1900 - val_acc: 0.9103\n",
      "Epoch 116/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1895 - acc: 0.9103 - val_loss: 0.1842 - val_acc: 0.9103\n",
      "Epoch 117/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1785 - acc: 0.9193 - val_loss: 0.1706 - val_acc: 0.9193\n",
      "Epoch 118/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1777 - acc: 0.9148 - val_loss: 0.1686 - val_acc: 0.9193\n",
      "Epoch 119/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1798 - acc: 0.9148 - val_loss: 0.1711 - val_acc: 0.9238\n",
      "Epoch 120/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1744 - acc: 0.9193 - val_loss: 0.1645 - val_acc: 0.9238\n",
      "Epoch 121/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 0s 126us/step - loss: 0.1708 - acc: 0.9238 - val_loss: 0.1677 - val_acc: 0.9283\n",
      "Epoch 122/800\n",
      "223/223 [==============================] - 0s 134us/step - loss: 0.1781 - acc: 0.9103 - val_loss: 0.1725 - val_acc: 0.9148\n",
      "Epoch 123/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1784 - acc: 0.9148 - val_loss: 0.1726 - val_acc: 0.9193\n",
      "Epoch 124/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.1699 - acc: 0.9238 - val_loss: 0.1679 - val_acc: 0.9193\n",
      "Epoch 125/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.1671 - acc: 0.9193 - val_loss: 0.1615 - val_acc: 0.9283\n",
      "Epoch 126/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1648 - acc: 0.9283 - val_loss: 0.1610 - val_acc: 0.9283\n",
      "Epoch 127/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1654 - acc: 0.9238 - val_loss: 0.1625 - val_acc: 0.9238\n",
      "Epoch 128/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1667 - acc: 0.9283 - val_loss: 0.1646 - val_acc: 0.9283\n",
      "Epoch 129/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1710 - acc: 0.9148 - val_loss: 0.1637 - val_acc: 0.9238\n",
      "Epoch 130/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1903 - acc: 0.9148 - val_loss: 0.1784 - val_acc: 0.9148\n",
      "Epoch 131/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1853 - acc: 0.9193 - val_loss: 0.1652 - val_acc: 0.9283\n",
      "Epoch 132/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1868 - acc: 0.9103 - val_loss: 0.1767 - val_acc: 0.8924\n",
      "Epoch 133/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1769 - acc: 0.9103 - val_loss: 0.1762 - val_acc: 0.9103\n",
      "Epoch 134/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1778 - acc: 0.9013 - val_loss: 0.1790 - val_acc: 0.9103\n",
      "Epoch 135/800\n",
      "223/223 [==============================] - 0s 139us/step - loss: 0.1979 - acc: 0.8924 - val_loss: 0.1653 - val_acc: 0.9193\n",
      "Epoch 136/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1818 - acc: 0.9193 - val_loss: 0.2017 - val_acc: 0.9058\n",
      "Epoch 137/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1716 - acc: 0.9238 - val_loss: 0.1926 - val_acc: 0.9058\n",
      "Epoch 138/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1810 - acc: 0.9058 - val_loss: 0.1885 - val_acc: 0.9013\n",
      "Epoch 139/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1870 - acc: 0.8969 - val_loss: 0.1575 - val_acc: 0.9327\n",
      "Epoch 140/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1822 - acc: 0.9013 - val_loss: 0.1706 - val_acc: 0.9238\n",
      "Epoch 141/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.1786 - acc: 0.9058 - val_loss: 0.1696 - val_acc: 0.9238\n",
      "Epoch 142/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1804 - acc: 0.9283 - val_loss: 0.1844 - val_acc: 0.9103\n",
      "Epoch 143/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1800 - acc: 0.9058 - val_loss: 0.1548 - val_acc: 0.9372\n",
      "Epoch 144/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.1650 - acc: 0.9193 - val_loss: 0.1568 - val_acc: 0.9327\n",
      "Epoch 145/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1597 - acc: 0.9327 - val_loss: 0.1582 - val_acc: 0.9327\n",
      "Epoch 146/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1652 - acc: 0.9238 - val_loss: 0.1592 - val_acc: 0.9283\n",
      "Epoch 147/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1618 - acc: 0.9193 - val_loss: 0.1565 - val_acc: 0.9417\n",
      "Epoch 148/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1684 - acc: 0.9193 - val_loss: 0.1804 - val_acc: 0.9103\n",
      "Epoch 149/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1900 - acc: 0.9058 - val_loss: 0.1721 - val_acc: 0.9193\n",
      "Epoch 150/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.2205 - acc: 0.8969 - val_loss: 0.2657 - val_acc: 0.8655\n",
      "Epoch 151/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2494 - acc: 0.8879 - val_loss: 0.1986 - val_acc: 0.8924\n",
      "Epoch 152/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1926 - acc: 0.8879 - val_loss: 0.2239 - val_acc: 0.9013\n",
      "Epoch 153/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2217 - acc: 0.9013 - val_loss: 0.2253 - val_acc: 0.8744\n",
      "Epoch 154/800\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.3242 - acc: 0.812 - 0s 121us/step - loss: 0.2267 - acc: 0.8789 - val_loss: 0.1965 - val_acc: 0.9103\n",
      "Epoch 155/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1931 - acc: 0.9193 - val_loss: 0.1808 - val_acc: 0.9283\n",
      "Epoch 156/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1849 - acc: 0.9283 - val_loss: 0.1698 - val_acc: 0.9193\n",
      "Epoch 157/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2096 - acc: 0.8879 - val_loss: 0.2085 - val_acc: 0.8969\n",
      "Epoch 158/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2248 - acc: 0.8924 - val_loss: 0.2636 - val_acc: 0.8655\n",
      "Epoch 159/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1957 - acc: 0.9103 - val_loss: 0.1649 - val_acc: 0.9417\n",
      "Epoch 160/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1672 - acc: 0.9283 - val_loss: 0.1552 - val_acc: 0.9327\n",
      "Epoch 161/800\n",
      "223/223 [==============================] - 0s 144us/step - loss: 0.1606 - acc: 0.9283 - val_loss: 0.1546 - val_acc: 0.9238\n",
      "Epoch 162/800\n",
      "223/223 [==============================] - 0s 152us/step - loss: 0.1604 - acc: 0.9283 - val_loss: 0.1566 - val_acc: 0.9238\n",
      "Epoch 163/800\n",
      "223/223 [==============================] - 0s 155us/step - loss: 0.1612 - acc: 0.9372 - val_loss: 0.1575 - val_acc: 0.9283\n",
      "Epoch 164/800\n",
      "223/223 [==============================] - 0s 143us/step - loss: 0.1665 - acc: 0.9238 - val_loss: 0.1510 - val_acc: 0.9238\n",
      "Epoch 165/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1621 - acc: 0.9283 - val_loss: 0.1509 - val_acc: 0.9327\n",
      "Epoch 166/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1584 - acc: 0.9283 - val_loss: 0.1451 - val_acc: 0.9372\n",
      "Epoch 167/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1592 - acc: 0.9193 - val_loss: 0.1521 - val_acc: 0.9372\n",
      "Epoch 168/800\n",
      "223/223 [==============================] - 0s 146us/step - loss: 0.1501 - acc: 0.9327 - val_loss: 0.1491 - val_acc: 0.9372\n",
      "Epoch 169/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1575 - acc: 0.9372 - val_loss: 0.1616 - val_acc: 0.9238\n",
      "Epoch 170/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1570 - acc: 0.9238 - val_loss: 0.1466 - val_acc: 0.9327\n",
      "Epoch 171/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1525 - acc: 0.9327 - val_loss: 0.1639 - val_acc: 0.9238\n",
      "Epoch 172/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1653 - acc: 0.9193 - val_loss: 0.1743 - val_acc: 0.9013\n",
      "Epoch 173/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1751 - acc: 0.9148 - val_loss: 0.2342 - val_acc: 0.8744\n",
      "Epoch 174/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1957 - acc: 0.9148 - val_loss: 0.1627 - val_acc: 0.9283\n",
      "Epoch 175/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1831 - acc: 0.9148 - val_loss: 0.1603 - val_acc: 0.9372\n",
      "Epoch 176/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.2004 - acc: 0.8969 - val_loss: 0.1517 - val_acc: 0.9372\n",
      "Epoch 177/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1497 - acc: 0.9417 - val_loss: 0.1429 - val_acc: 0.9372\n",
      "Epoch 178/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1545 - acc: 0.9327 - val_loss: 0.1457 - val_acc: 0.9372\n",
      "Epoch 179/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1522 - acc: 0.9327 - val_loss: 0.1676 - val_acc: 0.9103\n",
      "Epoch 180/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "223/223 [==============================] - 0s 125us/step - loss: 0.1648 - acc: 0.9103 - val_loss: 0.1504 - val_acc: 0.9193\n",
      "Epoch 181/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1683 - acc: 0.9238 - val_loss: 0.1434 - val_acc: 0.9193\n",
      "Epoch 182/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1547 - acc: 0.9238 - val_loss: 0.1430 - val_acc: 0.9417\n",
      "Epoch 183/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1513 - acc: 0.9417 - val_loss: 0.1382 - val_acc: 0.9462\n",
      "Epoch 184/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1544 - acc: 0.9327 - val_loss: 0.1368 - val_acc: 0.9417\n",
      "Epoch 185/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1626 - acc: 0.9148 - val_loss: 0.1458 - val_acc: 0.9327\n",
      "Epoch 186/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1848 - acc: 0.9283 - val_loss: 0.1590 - val_acc: 0.9327\n",
      "Epoch 187/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2042 - acc: 0.8969 - val_loss: 0.2402 - val_acc: 0.9193\n",
      "Epoch 188/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1919 - acc: 0.9193 - val_loss: 0.2084 - val_acc: 0.9013\n",
      "Epoch 189/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1714 - acc: 0.9193 - val_loss: 0.1494 - val_acc: 0.9417\n",
      "Epoch 190/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1674 - acc: 0.9193 - val_loss: 0.1506 - val_acc: 0.9283\n",
      "Epoch 191/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1610 - acc: 0.9283 - val_loss: 0.1431 - val_acc: 0.9372\n",
      "Epoch 192/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1432 - acc: 0.9372 - val_loss: 0.1686 - val_acc: 0.9103\n",
      "Epoch 193/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1619 - acc: 0.9148 - val_loss: 0.1399 - val_acc: 0.9462\n",
      "Epoch 194/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1668 - acc: 0.9327 - val_loss: 0.1569 - val_acc: 0.9372\n",
      "Epoch 195/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1558 - acc: 0.9238 - val_loss: 0.1357 - val_acc: 0.9327\n",
      "Epoch 196/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1396 - acc: 0.9372 - val_loss: 0.1391 - val_acc: 0.9417\n",
      "Epoch 197/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1455 - acc: 0.9417 - val_loss: 0.1310 - val_acc: 0.9507\n",
      "Epoch 198/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1352 - acc: 0.9462 - val_loss: 0.1291 - val_acc: 0.9462\n",
      "Epoch 199/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1354 - acc: 0.9417 - val_loss: 0.1268 - val_acc: 0.9462\n",
      "Epoch 200/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1287 - acc: 0.9372 - val_loss: 0.1286 - val_acc: 0.9462\n",
      "Epoch 201/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.1340 - acc: 0.9327 - val_loss: 0.1306 - val_acc: 0.9462\n",
      "Epoch 202/800\n",
      "223/223 [==============================] - 0s 155us/step - loss: 0.1361 - acc: 0.9462 - val_loss: 0.1544 - val_acc: 0.9238\n",
      "Epoch 203/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.1468 - acc: 0.9238 - val_loss: 0.1286 - val_acc: 0.9507\n",
      "Epoch 204/800\n",
      "223/223 [==============================] - 0s 139us/step - loss: 0.1338 - acc: 0.9462 - val_loss: 0.1275 - val_acc: 0.9417\n",
      "Epoch 205/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1305 - acc: 0.9417 - val_loss: 0.1271 - val_acc: 0.9507\n",
      "Epoch 206/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1296 - acc: 0.9462 - val_loss: 0.1234 - val_acc: 0.9507\n",
      "Epoch 207/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1379 - acc: 0.9372 - val_loss: 0.1503 - val_acc: 0.9327\n",
      "Epoch 208/800\n",
      "223/223 [==============================] - 0s 141us/step - loss: 0.1457 - acc: 0.9238 - val_loss: 0.1590 - val_acc: 0.9193\n",
      "Epoch 209/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1665 - acc: 0.9372 - val_loss: 0.1215 - val_acc: 0.9462\n",
      "Epoch 210/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.2044 - acc: 0.8744 - val_loss: 0.2199 - val_acc: 0.8834\n",
      "Epoch 211/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1902 - acc: 0.9103 - val_loss: 0.1724 - val_acc: 0.9148\n",
      "Epoch 212/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1876 - acc: 0.9058 - val_loss: 0.1771 - val_acc: 0.9327\n",
      "Epoch 213/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1852 - acc: 0.9193 - val_loss: 0.1583 - val_acc: 0.9372\n",
      "Epoch 214/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1575 - acc: 0.9327 - val_loss: 0.1445 - val_acc: 0.9507\n",
      "Epoch 215/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1835 - acc: 0.9193 - val_loss: 0.1656 - val_acc: 0.9148\n",
      "Epoch 216/800\n",
      "223/223 [==============================] - 0s 141us/step - loss: 0.1951 - acc: 0.9148 - val_loss: 0.1767 - val_acc: 0.9238\n",
      "Epoch 217/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2040 - acc: 0.9013 - val_loss: 0.2326 - val_acc: 0.8700\n",
      "Epoch 218/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1944 - acc: 0.9238 - val_loss: 0.1630 - val_acc: 0.9327\n",
      "Epoch 219/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1593 - acc: 0.9238 - val_loss: 0.1367 - val_acc: 0.9372\n",
      "Epoch 220/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1523 - acc: 0.9372 - val_loss: 0.1599 - val_acc: 0.9193\n",
      "Epoch 221/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1577 - acc: 0.9283 - val_loss: 0.1328 - val_acc: 0.9462\n",
      "Epoch 222/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1445 - acc: 0.9417 - val_loss: 0.1386 - val_acc: 0.9372\n",
      "Epoch 223/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1953 - acc: 0.9058 - val_loss: 0.2013 - val_acc: 0.8924\n",
      "Epoch 224/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2149 - acc: 0.8834 - val_loss: 0.1600 - val_acc: 0.9372\n",
      "Epoch 225/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.2008 - acc: 0.9058 - val_loss: 0.1678 - val_acc: 0.9238\n",
      "Epoch 226/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.2066 - acc: 0.9148 - val_loss: 0.2582 - val_acc: 0.8341\n",
      "Epoch 227/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2436 - acc: 0.8789 - val_loss: 0.1790 - val_acc: 0.9103\n",
      "Epoch 228/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1871 - acc: 0.9327 - val_loss: 0.1525 - val_acc: 0.9372\n",
      "Epoch 229/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1736 - acc: 0.9103 - val_loss: 0.1643 - val_acc: 0.9238\n",
      "Epoch 230/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1744 - acc: 0.9193 - val_loss: 0.1901 - val_acc: 0.9238\n",
      "Epoch 231/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1927 - acc: 0.9148 - val_loss: 0.1757 - val_acc: 0.9283\n",
      "Epoch 232/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1676 - acc: 0.9372 - val_loss: 0.1296 - val_acc: 0.9372\n",
      "Epoch 233/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1381 - acc: 0.9238 - val_loss: 0.1478 - val_acc: 0.9148\n",
      "Epoch 234/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1645 - acc: 0.9238 - val_loss: 0.1539 - val_acc: 0.9193\n",
      "Epoch 235/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1418 - acc: 0.9417 - val_loss: 0.1608 - val_acc: 0.9148\n",
      "Epoch 236/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.1502 - acc: 0.9238 - val_loss: 0.1192 - val_acc: 0.9596\n",
      "Epoch 237/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1249 - acc: 0.9552 - val_loss: 0.1190 - val_acc: 0.9552\n",
      "Epoch 238/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1227 - acc: 0.9372 - val_loss: 0.1201 - val_acc: 0.9552\n",
      "Epoch 239/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.1213 - acc: 0.9507 - val_loss: 0.1141 - val_acc: 0.9686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1285 - acc: 0.9417 - val_loss: 0.1601 - val_acc: 0.9103\n",
      "Epoch 241/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.1650 - acc: 0.9148 - val_loss: 0.1130 - val_acc: 0.9641\n",
      "Epoch 242/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1599 - acc: 0.9462 - val_loss: 0.1830 - val_acc: 0.9193\n",
      "Epoch 243/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.2175 - acc: 0.8834 - val_loss: 0.2213 - val_acc: 0.8834\n",
      "Epoch 244/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1940 - acc: 0.9058 - val_loss: 0.1379 - val_acc: 0.9462\n",
      "Epoch 245/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1517 - acc: 0.9372 - val_loss: 0.1399 - val_acc: 0.9417\n",
      "Epoch 246/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1356 - acc: 0.9417 - val_loss: 0.1218 - val_acc: 0.9462\n",
      "Epoch 247/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1223 - acc: 0.9507 - val_loss: 0.1154 - val_acc: 0.9507\n",
      "Epoch 248/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1195 - acc: 0.9462 - val_loss: 0.1129 - val_acc: 0.9507\n",
      "Epoch 249/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1192 - acc: 0.9552 - val_loss: 0.1112 - val_acc: 0.9641\n",
      "Epoch 250/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1200 - acc: 0.9417 - val_loss: 0.1320 - val_acc: 0.9507\n",
      "Epoch 251/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1386 - acc: 0.9417 - val_loss: 0.1130 - val_acc: 0.9596\n",
      "Epoch 252/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1264 - acc: 0.9596 - val_loss: 0.1114 - val_acc: 0.9641\n",
      "Epoch 253/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1253 - acc: 0.9552 - val_loss: 0.1193 - val_acc: 0.9596\n",
      "Epoch 254/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1212 - acc: 0.9417 - val_loss: 0.1128 - val_acc: 0.9552\n",
      "Epoch 255/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1186 - acc: 0.9507 - val_loss: 0.1134 - val_acc: 0.9686\n",
      "Epoch 256/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1191 - acc: 0.9552 - val_loss: 0.1068 - val_acc: 0.9596\n",
      "Epoch 257/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1150 - acc: 0.9552 - val_loss: 0.1210 - val_acc: 0.9507\n",
      "Epoch 258/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1177 - acc: 0.9462 - val_loss: 0.1388 - val_acc: 0.9327\n",
      "Epoch 259/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1358 - acc: 0.9417 - val_loss: 0.1179 - val_acc: 0.9596\n",
      "Epoch 260/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1181 - acc: 0.9552 - val_loss: 0.1055 - val_acc: 0.9552\n",
      "Epoch 261/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1161 - acc: 0.9507 - val_loss: 0.1121 - val_acc: 0.9641\n",
      "Epoch 262/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1088 - acc: 0.9686 - val_loss: 0.1086 - val_acc: 0.9596\n",
      "Epoch 263/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1115 - acc: 0.9641 - val_loss: 0.1032 - val_acc: 0.9776\n",
      "Epoch 264/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1063 - acc: 0.9641 - val_loss: 0.0979 - val_acc: 0.9731\n",
      "Epoch 265/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1035 - acc: 0.9731 - val_loss: 0.0999 - val_acc: 0.9596\n",
      "Epoch 266/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1054 - acc: 0.9596 - val_loss: 0.0972 - val_acc: 0.9686\n",
      "Epoch 267/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1036 - acc: 0.9686 - val_loss: 0.1009 - val_acc: 0.9641\n",
      "Epoch 268/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1037 - acc: 0.9552 - val_loss: 0.1014 - val_acc: 0.9686\n",
      "Epoch 269/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1026 - acc: 0.9731 - val_loss: 0.1009 - val_acc: 0.9686\n",
      "Epoch 270/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1032 - acc: 0.9596 - val_loss: 0.0989 - val_acc: 0.9686\n",
      "Epoch 271/800\n",
      "223/223 [==============================] - 0s 146us/step - loss: 0.1035 - acc: 0.9686 - val_loss: 0.0988 - val_acc: 0.9641\n",
      "Epoch 272/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1114 - acc: 0.9641 - val_loss: 0.1059 - val_acc: 0.9686\n",
      "Epoch 273/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1068 - acc: 0.9552 - val_loss: 0.0942 - val_acc: 0.9731\n",
      "Epoch 274/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0969 - acc: 0.9731 - val_loss: 0.0929 - val_acc: 0.9731\n",
      "Epoch 275/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0936 - acc: 0.9641 - val_loss: 0.0918 - val_acc: 0.9731\n",
      "Epoch 276/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1023 - acc: 0.9641 - val_loss: 0.0907 - val_acc: 0.9776\n",
      "Epoch 277/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0938 - acc: 0.9731 - val_loss: 0.1022 - val_acc: 0.9686\n",
      "Epoch 278/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1005 - acc: 0.9596 - val_loss: 0.0948 - val_acc: 0.9641\n",
      "Epoch 279/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0997 - acc: 0.9641 - val_loss: 0.0923 - val_acc: 0.9686\n",
      "Epoch 280/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0962 - acc: 0.9686 - val_loss: 0.1028 - val_acc: 0.9641\n",
      "Epoch 281/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.1082 - acc: 0.9507 - val_loss: 0.1091 - val_acc: 0.9462\n",
      "Epoch 282/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1411 - acc: 0.9327 - val_loss: 0.1389 - val_acc: 0.9283\n",
      "Epoch 283/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.1194 - acc: 0.9417 - val_loss: 0.1003 - val_acc: 0.9641\n",
      "Epoch 284/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1116 - acc: 0.9641 - val_loss: 0.0935 - val_acc: 0.9731\n",
      "Epoch 285/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0903 - acc: 0.9641 - val_loss: 0.0885 - val_acc: 0.9731\n",
      "Epoch 286/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0910 - acc: 0.9686 - val_loss: 0.0886 - val_acc: 0.9731\n",
      "Epoch 287/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0904 - acc: 0.9731 - val_loss: 0.0897 - val_acc: 0.9776\n",
      "Epoch 288/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0912 - acc: 0.9641 - val_loss: 0.0914 - val_acc: 0.9731\n",
      "Epoch 289/800\n",
      "223/223 [==============================] - 0s 139us/step - loss: 0.0982 - acc: 0.9731 - val_loss: 0.0952 - val_acc: 0.9731\n",
      "Epoch 290/800\n",
      "223/223 [==============================] - 0s 134us/step - loss: 0.0934 - acc: 0.9686 - val_loss: 0.0865 - val_acc: 0.9731\n",
      "Epoch 291/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0909 - acc: 0.9641 - val_loss: 0.0886 - val_acc: 0.9596\n",
      "Epoch 292/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0902 - acc: 0.9686 - val_loss: 0.0873 - val_acc: 0.9731\n",
      "Epoch 293/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0892 - acc: 0.9686 - val_loss: 0.0833 - val_acc: 0.9731\n",
      "Epoch 294/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0854 - acc: 0.9776 - val_loss: 0.0869 - val_acc: 0.9686\n",
      "Epoch 295/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0898 - acc: 0.9641 - val_loss: 0.0854 - val_acc: 0.9776\n",
      "Epoch 296/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0885 - acc: 0.9686 - val_loss: 0.0818 - val_acc: 0.9821\n",
      "Epoch 297/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0874 - acc: 0.9686 - val_loss: 0.0961 - val_acc: 0.9731\n",
      "Epoch 298/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0994 - acc: 0.9686 - val_loss: 0.1007 - val_acc: 0.9686\n",
      "Epoch 299/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0937 - acc: 0.9686 - val_loss: 0.0989 - val_acc: 0.9686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1072 - acc: 0.9507 - val_loss: 0.0936 - val_acc: 0.9731\n",
      "Epoch 301/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0971 - acc: 0.9641 - val_loss: 0.0855 - val_acc: 0.9731\n",
      "Epoch 302/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0961 - acc: 0.9507 - val_loss: 0.0846 - val_acc: 0.9776\n",
      "Epoch 303/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0914 - acc: 0.9731 - val_loss: 0.0801 - val_acc: 0.9686\n",
      "Epoch 304/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0899 - acc: 0.9641 - val_loss: 0.0998 - val_acc: 0.9686\n",
      "Epoch 305/800\n",
      "223/223 [==============================] - 0s 141us/step - loss: 0.1050 - acc: 0.9596 - val_loss: 0.0836 - val_acc: 0.9776\n",
      "Epoch 306/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0932 - acc: 0.9641 - val_loss: 0.0937 - val_acc: 0.9865\n",
      "Epoch 307/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1246 - acc: 0.9417 - val_loss: 0.0968 - val_acc: 0.9731\n",
      "Epoch 308/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1345 - acc: 0.9552 - val_loss: 0.2945 - val_acc: 0.8789\n",
      "Epoch 309/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.2867 - acc: 0.8655 - val_loss: 0.3510 - val_acc: 0.8430\n",
      "Epoch 310/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2400 - acc: 0.8834 - val_loss: 0.1732 - val_acc: 0.9148\n",
      "Epoch 311/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.2695 - acc: 0.8924 - val_loss: 0.2345 - val_acc: 0.8969\n",
      "Epoch 312/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2631 - acc: 0.8834 - val_loss: 0.1676 - val_acc: 0.9417\n",
      "Epoch 313/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1412 - acc: 0.9417 - val_loss: 0.1303 - val_acc: 0.9372\n",
      "Epoch 314/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1360 - acc: 0.9193 - val_loss: 0.1111 - val_acc: 0.9596\n",
      "Epoch 315/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1136 - acc: 0.9462 - val_loss: 0.1171 - val_acc: 0.9731\n",
      "Epoch 316/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1143 - acc: 0.9462 - val_loss: 0.0925 - val_acc: 0.9731\n",
      "Epoch 317/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0968 - acc: 0.9686 - val_loss: 0.0880 - val_acc: 0.9686\n",
      "Epoch 318/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0908 - acc: 0.9686 - val_loss: 0.0847 - val_acc: 0.9686\n",
      "Epoch 319/800\n",
      "223/223 [==============================] - 0s 139us/step - loss: 0.0945 - acc: 0.9596 - val_loss: 0.0865 - val_acc: 0.9821\n",
      "Epoch 320/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0880 - acc: 0.9731 - val_loss: 0.0814 - val_acc: 0.9686\n",
      "Epoch 321/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0955 - acc: 0.9641 - val_loss: 0.0769 - val_acc: 0.9731\n",
      "Epoch 322/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1015 - acc: 0.9596 - val_loss: 0.0993 - val_acc: 0.9641\n",
      "Epoch 323/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0977 - acc: 0.9686 - val_loss: 0.0794 - val_acc: 0.9776\n",
      "Epoch 324/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0810 - acc: 0.9821 - val_loss: 0.0767 - val_acc: 0.9776\n",
      "Epoch 325/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0830 - acc: 0.9731 - val_loss: 0.0774 - val_acc: 0.9821\n",
      "Epoch 326/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0827 - acc: 0.9686 - val_loss: 0.0740 - val_acc: 0.9731\n",
      "Epoch 327/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0839 - acc: 0.9596 - val_loss: 0.0761 - val_acc: 0.9731\n",
      "Epoch 328/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0837 - acc: 0.9821 - val_loss: 0.0750 - val_acc: 0.9731\n",
      "Epoch 329/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0918 - acc: 0.9731 - val_loss: 0.0844 - val_acc: 0.9776\n",
      "Epoch 330/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0798 - acc: 0.9776 - val_loss: 0.0772 - val_acc: 0.9776\n",
      "Epoch 331/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0805 - acc: 0.9731 - val_loss: 0.0717 - val_acc: 0.9821\n",
      "Epoch 332/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0745 - acc: 0.9731 - val_loss: 0.0754 - val_acc: 0.9821\n",
      "Epoch 333/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0772 - acc: 0.9731 - val_loss: 0.0700 - val_acc: 0.9821\n",
      "Epoch 334/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0780 - acc: 0.9731 - val_loss: 0.0706 - val_acc: 0.9776\n",
      "Epoch 335/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0702 - acc: 0.9776 - val_loss: 0.0714 - val_acc: 0.9731\n",
      "Epoch 336/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0766 - acc: 0.9686 - val_loss: 0.0672 - val_acc: 0.9731\n",
      "Epoch 337/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0771 - acc: 0.9776 - val_loss: 0.0852 - val_acc: 0.9596\n",
      "Epoch 338/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0943 - acc: 0.9641 - val_loss: 0.0762 - val_acc: 0.9821\n",
      "Epoch 339/800\n",
      "223/223 [==============================] - 0s 150us/step - loss: 0.0861 - acc: 0.9731 - val_loss: 0.0817 - val_acc: 0.9821\n",
      "Epoch 340/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1065 - acc: 0.9507 - val_loss: 0.0826 - val_acc: 0.9776\n",
      "Epoch 341/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1313 - acc: 0.9507 - val_loss: 0.0771 - val_acc: 0.9821\n",
      "Epoch 342/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0921 - acc: 0.9686 - val_loss: 0.0761 - val_acc: 0.9821\n",
      "Epoch 343/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0777 - acc: 0.9686 - val_loss: 0.0708 - val_acc: 0.9821\n",
      "Epoch 344/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0733 - acc: 0.9641 - val_loss: 0.0699 - val_acc: 0.9731\n",
      "Epoch 345/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0731 - acc: 0.9821 - val_loss: 0.0680 - val_acc: 0.9776\n",
      "Epoch 346/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0702 - acc: 0.9731 - val_loss: 0.0690 - val_acc: 0.9821\n",
      "Epoch 347/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0744 - acc: 0.9821 - val_loss: 0.0726 - val_acc: 0.9776\n",
      "Epoch 348/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0973 - acc: 0.9552 - val_loss: 0.0780 - val_acc: 0.9641\n",
      "Epoch 349/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0833 - acc: 0.9686 - val_loss: 0.0660 - val_acc: 0.9731\n",
      "Epoch 350/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0695 - acc: 0.9821 - val_loss: 0.0674 - val_acc: 0.9821\n",
      "Epoch 351/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0749 - acc: 0.9776 - val_loss: 0.0682 - val_acc: 0.9821\n",
      "Epoch 352/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0750 - acc: 0.9821 - val_loss: 0.0656 - val_acc: 0.9821\n",
      "Epoch 353/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0684 - acc: 0.9731 - val_loss: 0.0713 - val_acc: 0.9731\n",
      "Epoch 354/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0799 - acc: 0.9641 - val_loss: 0.0667 - val_acc: 0.9821\n",
      "Epoch 355/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0777 - acc: 0.9821 - val_loss: 0.0655 - val_acc: 0.9821\n",
      "Epoch 356/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0676 - acc: 0.9776 - val_loss: 0.0674 - val_acc: 0.9821\n",
      "Epoch 357/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0709 - acc: 0.9776 - val_loss: 0.0651 - val_acc: 0.9731\n",
      "Epoch 358/800\n",
      "223/223 [==============================] - 0s 134us/step - loss: 0.0635 - acc: 0.9821 - val_loss: 0.0604 - val_acc: 0.9865\n",
      "Epoch 359/800\n",
      "223/223 [==============================] - ETA: 0s - loss: 0.0261 - acc: 1.000 - 0s 137us/step - loss: 0.0600 - acc: 0.9865 - val_loss: 0.0709 - val_acc: 0.9776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0833 - acc: 0.9821 - val_loss: 0.0701 - val_acc: 0.9821\n",
      "Epoch 361/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.0831 - acc: 0.9641 - val_loss: 0.1252 - val_acc: 0.9462\n",
      "Epoch 362/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1310 - acc: 0.9417 - val_loss: 0.0695 - val_acc: 0.9641\n",
      "Epoch 363/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1283 - acc: 0.9372 - val_loss: 0.3290 - val_acc: 0.9013\n",
      "Epoch 364/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.3129 - acc: 0.8744 - val_loss: 0.4380 - val_acc: 0.8520\n",
      "Epoch 365/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.4817 - acc: 0.8520 - val_loss: 0.2598 - val_acc: 0.8744\n",
      "Epoch 366/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2196 - acc: 0.9058 - val_loss: 0.3090 - val_acc: 0.9013\n",
      "Epoch 367/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.2475 - acc: 0.9193 - val_loss: 0.1686 - val_acc: 0.9193\n",
      "Epoch 368/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1728 - acc: 0.9193 - val_loss: 0.1402 - val_acc: 0.9283\n",
      "Epoch 369/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1327 - acc: 0.9417 - val_loss: 0.1070 - val_acc: 0.9462\n",
      "Epoch 370/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1230 - acc: 0.9372 - val_loss: 0.0898 - val_acc: 0.9776\n",
      "Epoch 371/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0912 - acc: 0.9731 - val_loss: 0.0819 - val_acc: 0.9686\n",
      "Epoch 372/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0828 - acc: 0.9686 - val_loss: 0.0732 - val_acc: 0.9686\n",
      "Epoch 373/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.1028 - acc: 0.9552 - val_loss: 0.0744 - val_acc: 0.9821\n",
      "Epoch 374/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0991 - acc: 0.9596 - val_loss: 0.0756 - val_acc: 0.9731\n",
      "Epoch 375/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0857 - acc: 0.9596 - val_loss: 0.0900 - val_acc: 0.9596\n",
      "Epoch 376/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.0833 - acc: 0.9686 - val_loss: 0.0773 - val_acc: 0.9731\n",
      "Epoch 377/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0928 - acc: 0.9641 - val_loss: 0.0921 - val_acc: 0.9596\n",
      "Epoch 378/800\n",
      "223/223 [==============================] - 0s 141us/step - loss: 0.0765 - acc: 0.9776 - val_loss: 0.0935 - val_acc: 0.9686\n",
      "Epoch 379/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0848 - acc: 0.9686 - val_loss: 0.0857 - val_acc: 0.9641\n",
      "Epoch 380/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0838 - acc: 0.9596 - val_loss: 0.0706 - val_acc: 0.9731\n",
      "Epoch 381/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0716 - acc: 0.9821 - val_loss: 0.0663 - val_acc: 0.9865\n",
      "Epoch 382/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0730 - acc: 0.9731 - val_loss: 0.0812 - val_acc: 0.9776\n",
      "Epoch 383/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0709 - acc: 0.9776 - val_loss: 0.0705 - val_acc: 0.9865\n",
      "Epoch 384/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0729 - acc: 0.9865 - val_loss: 0.0656 - val_acc: 0.9731\n",
      "Epoch 385/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0714 - acc: 0.9731 - val_loss: 0.0640 - val_acc: 0.9865\n",
      "Epoch 386/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0671 - acc: 0.9821 - val_loss: 0.0622 - val_acc: 0.9821\n",
      "Epoch 387/800\n",
      "223/223 [==============================] - 0s 134us/step - loss: 0.0702 - acc: 0.9731 - val_loss: 0.0607 - val_acc: 0.9776\n",
      "Epoch 388/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.0657 - acc: 0.9731 - val_loss: 0.0633 - val_acc: 0.9776\n",
      "Epoch 389/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0731 - acc: 0.9731 - val_loss: 0.0596 - val_acc: 0.9821\n",
      "Epoch 390/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0630 - acc: 0.9821 - val_loss: 0.0590 - val_acc: 0.9821\n",
      "Epoch 391/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0621 - acc: 0.9731 - val_loss: 0.0602 - val_acc: 0.9821\n",
      "Epoch 392/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0634 - acc: 0.9776 - val_loss: 0.0552 - val_acc: 0.9865\n",
      "Epoch 393/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0597 - acc: 0.9865 - val_loss: 0.0538 - val_acc: 0.9865\n",
      "Epoch 394/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0666 - acc: 0.9776 - val_loss: 0.0707 - val_acc: 0.9821\n",
      "Epoch 395/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0613 - acc: 0.9865 - val_loss: 0.0579 - val_acc: 0.9865\n",
      "Epoch 396/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0651 - acc: 0.9821 - val_loss: 0.0743 - val_acc: 0.9821\n",
      "Epoch 397/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0686 - acc: 0.9776 - val_loss: 0.0656 - val_acc: 0.9731\n",
      "Epoch 398/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.0636 - acc: 0.9776 - val_loss: 0.0613 - val_acc: 0.9865\n",
      "Epoch 399/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0643 - acc: 0.9865 - val_loss: 0.0778 - val_acc: 0.9686\n",
      "Epoch 400/800\n",
      "223/223 [==============================] - 0s 134us/step - loss: 0.0722 - acc: 0.9821 - val_loss: 0.0822 - val_acc: 0.9731\n",
      "Epoch 401/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0718 - acc: 0.9731 - val_loss: 0.0727 - val_acc: 0.9776\n",
      "Epoch 402/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1059 - acc: 0.9641 - val_loss: 0.0779 - val_acc: 0.9821\n",
      "Epoch 403/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1301 - acc: 0.9507 - val_loss: 0.0997 - val_acc: 0.9731\n",
      "Epoch 404/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.2172 - acc: 0.9283 - val_loss: 0.4741 - val_acc: 0.8341\n",
      "Epoch 405/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.3439 - acc: 0.8879 - val_loss: 0.1436 - val_acc: 0.9417\n",
      "Epoch 406/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.2426 - acc: 0.8969 - val_loss: 0.3100 - val_acc: 0.8789\n",
      "Epoch 407/800\n",
      "223/223 [==============================] - 0s 152us/step - loss: 0.3456 - acc: 0.8700 - val_loss: 0.1623 - val_acc: 0.9507\n",
      "Epoch 408/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1868 - acc: 0.9148 - val_loss: 0.1097 - val_acc: 0.9507\n",
      "Epoch 409/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1456 - acc: 0.9283 - val_loss: 0.0974 - val_acc: 0.9641\n",
      "Epoch 410/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1229 - acc: 0.9552 - val_loss: 0.1003 - val_acc: 0.9596\n",
      "Epoch 411/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.1015 - acc: 0.9686 - val_loss: 0.1098 - val_acc: 0.9686\n",
      "Epoch 412/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0913 - acc: 0.9641 - val_loss: 0.0670 - val_acc: 0.9731\n",
      "Epoch 413/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0700 - acc: 0.9776 - val_loss: 0.0610 - val_acc: 0.9865\n",
      "Epoch 414/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0625 - acc: 0.9821 - val_loss: 0.0571 - val_acc: 0.9865\n",
      "Epoch 415/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0580 - acc: 0.9865 - val_loss: 0.0549 - val_acc: 0.9865\n",
      "Epoch 416/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0575 - acc: 0.9821 - val_loss: 0.0549 - val_acc: 0.9865\n",
      "Epoch 417/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0644 - acc: 0.9821 - val_loss: 0.0556 - val_acc: 0.9821\n",
      "Epoch 418/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0584 - acc: 0.9821 - val_loss: 0.0523 - val_acc: 0.9865\n",
      "Epoch 419/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0526 - acc: 0.9865 - val_loss: 0.0524 - val_acc: 0.9865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 420/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0578 - acc: 0.9865 - val_loss: 0.0512 - val_acc: 0.9865\n",
      "Epoch 421/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0583 - acc: 0.9776 - val_loss: 0.0539 - val_acc: 0.9865\n",
      "Epoch 422/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0552 - acc: 0.9865 - val_loss: 0.0497 - val_acc: 0.9865\n",
      "Epoch 423/800\n",
      "223/223 [==============================] - 0s 117us/step - loss: 0.0535 - acc: 0.9865 - val_loss: 0.0492 - val_acc: 0.9865\n",
      "Epoch 424/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0496 - acc: 0.9865 - val_loss: 0.0489 - val_acc: 0.9865\n",
      "Epoch 425/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0527 - acc: 0.9865 - val_loss: 0.0508 - val_acc: 0.9865\n",
      "Epoch 426/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0507 - acc: 0.9865 - val_loss: 0.0502 - val_acc: 0.9865\n",
      "Epoch 427/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0544 - acc: 0.9865 - val_loss: 0.0508 - val_acc: 0.9865\n",
      "Epoch 428/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0522 - acc: 0.9910 - val_loss: 0.0479 - val_acc: 0.9865\n",
      "Epoch 429/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0606 - acc: 0.9865 - val_loss: 0.0501 - val_acc: 0.9910\n",
      "Epoch 430/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0608 - acc: 0.9821 - val_loss: 0.0748 - val_acc: 0.9731\n",
      "Epoch 431/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0683 - acc: 0.9821 - val_loss: 0.0629 - val_acc: 0.9776\n",
      "Epoch 432/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0645 - acc: 0.9776 - val_loss: 0.0648 - val_acc: 0.9865\n",
      "Epoch 433/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1022 - acc: 0.9507 - val_loss: 0.1136 - val_acc: 0.9596\n",
      "Epoch 434/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1016 - acc: 0.9686 - val_loss: 0.0768 - val_acc: 0.9731\n",
      "Epoch 435/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0785 - acc: 0.9776 - val_loss: 0.0985 - val_acc: 0.9552\n",
      "Epoch 436/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0910 - acc: 0.9596 - val_loss: 0.0518 - val_acc: 0.9865\n",
      "Epoch 437/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0928 - acc: 0.9641 - val_loss: 0.0786 - val_acc: 0.9821\n",
      "Epoch 438/800\n",
      "223/223 [==============================] - 0s 141us/step - loss: 0.0822 - acc: 0.9776 - val_loss: 0.0794 - val_acc: 0.9731\n",
      "Epoch 439/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0776 - acc: 0.9686 - val_loss: 0.0751 - val_acc: 0.9731\n",
      "Epoch 440/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.0693 - acc: 0.9776 - val_loss: 0.0632 - val_acc: 0.9910\n",
      "Epoch 441/800\n",
      "223/223 [==============================] - 0s 153us/step - loss: 0.0648 - acc: 0.9865 - val_loss: 0.0784 - val_acc: 0.9641\n",
      "Epoch 442/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0802 - acc: 0.9641 - val_loss: 0.0759 - val_acc: 0.9686\n",
      "Epoch 443/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0813 - acc: 0.9731 - val_loss: 0.0720 - val_acc: 0.9731\n",
      "Epoch 444/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0650 - acc: 0.9731 - val_loss: 0.0643 - val_acc: 0.9776\n",
      "Epoch 445/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0629 - acc: 0.9731 - val_loss: 0.0675 - val_acc: 0.9686\n",
      "Epoch 446/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0687 - acc: 0.9731 - val_loss: 0.0543 - val_acc: 0.9910\n",
      "Epoch 447/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0550 - acc: 0.9910 - val_loss: 0.0492 - val_acc: 0.9865\n",
      "Epoch 448/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0556 - acc: 0.9776 - val_loss: 0.0517 - val_acc: 0.9865\n",
      "Epoch 449/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0599 - acc: 0.9821 - val_loss: 0.0467 - val_acc: 0.9821\n",
      "Epoch 450/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0574 - acc: 0.9776 - val_loss: 0.0457 - val_acc: 0.9865\n",
      "Epoch 451/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0596 - acc: 0.9821 - val_loss: 0.0575 - val_acc: 0.9910\n",
      "Epoch 452/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0667 - acc: 0.9821 - val_loss: 0.0860 - val_acc: 0.9596\n",
      "Epoch 453/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1159 - acc: 0.9462 - val_loss: 0.0695 - val_acc: 0.9776\n",
      "Epoch 454/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1008 - acc: 0.9686 - val_loss: 0.0509 - val_acc: 0.9865\n",
      "Epoch 455/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.0798 - acc: 0.9596 - val_loss: 0.0744 - val_acc: 0.9686\n",
      "Epoch 456/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2144 - acc: 0.9013 - val_loss: 0.1395 - val_acc: 0.9238\n",
      "Epoch 457/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1661 - acc: 0.9552 - val_loss: 0.0737 - val_acc: 0.9776\n",
      "Epoch 458/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1508 - acc: 0.9238 - val_loss: 0.0979 - val_acc: 0.9641\n",
      "Epoch 459/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1334 - acc: 0.9372 - val_loss: 0.0857 - val_acc: 0.9641\n",
      "Epoch 460/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1078 - acc: 0.9552 - val_loss: 0.0811 - val_acc: 0.9731\n",
      "Epoch 461/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1449 - acc: 0.9417 - val_loss: 0.2055 - val_acc: 0.9193\n",
      "Epoch 462/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1700 - acc: 0.9372 - val_loss: 0.0663 - val_acc: 0.9776\n",
      "Epoch 463/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1550 - acc: 0.9283 - val_loss: 0.1044 - val_acc: 0.9641\n",
      "Epoch 464/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2423 - acc: 0.8834 - val_loss: 0.1999 - val_acc: 0.9013\n",
      "Epoch 465/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1747 - acc: 0.9238 - val_loss: 0.3427 - val_acc: 0.8969\n",
      "Epoch 466/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.2656 - acc: 0.9148 - val_loss: 0.2369 - val_acc: 0.9103\n",
      "Epoch 467/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1167 - acc: 0.9462 - val_loss: 0.1517 - val_acc: 0.9283\n",
      "Epoch 468/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1195 - acc: 0.9552 - val_loss: 0.0918 - val_acc: 0.9596\n",
      "Epoch 469/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0978 - acc: 0.9507 - val_loss: 0.0672 - val_acc: 0.9686\n",
      "Epoch 470/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0627 - acc: 0.9686 - val_loss: 0.0802 - val_acc: 0.9686\n",
      "Epoch 471/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0909 - acc: 0.9731 - val_loss: 0.0554 - val_acc: 0.9776\n",
      "Epoch 472/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0787 - acc: 0.9596 - val_loss: 0.0490 - val_acc: 0.9910\n",
      "Epoch 473/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0628 - acc: 0.9865 - val_loss: 0.0475 - val_acc: 0.9910\n",
      "Epoch 474/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0502 - acc: 0.9821 - val_loss: 0.0469 - val_acc: 0.9865\n",
      "Epoch 475/800\n",
      "223/223 [==============================] - 0s 139us/step - loss: 0.0474 - acc: 0.9865 - val_loss: 0.0452 - val_acc: 0.9865\n",
      "Epoch 476/800\n",
      "223/223 [==============================] - 0s 139us/step - loss: 0.0457 - acc: 0.9910 - val_loss: 0.0452 - val_acc: 0.9910\n",
      "Epoch 477/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0482 - acc: 0.9821 - val_loss: 0.0436 - val_acc: 0.9865\n",
      "Epoch 478/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0474 - acc: 0.9910 - val_loss: 0.0434 - val_acc: 0.9910\n",
      "Epoch 479/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0457 - acc: 0.9865 - val_loss: 0.0465 - val_acc: 0.9865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/800\n",
      "223/223 [==============================] - 0s 134us/step - loss: 0.0464 - acc: 0.9821 - val_loss: 0.0418 - val_acc: 0.9865\n",
      "Epoch 481/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0437 - acc: 0.9865 - val_loss: 0.0438 - val_acc: 0.9865\n",
      "Epoch 482/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0452 - acc: 0.9865 - val_loss: 0.0454 - val_acc: 0.9865\n",
      "Epoch 483/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0659 - acc: 0.9641 - val_loss: 0.0559 - val_acc: 0.9865\n",
      "Epoch 484/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0641 - acc: 0.9776 - val_loss: 0.0495 - val_acc: 0.9821\n",
      "Epoch 485/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0622 - acc: 0.9731 - val_loss: 0.0567 - val_acc: 0.9776\n",
      "Epoch 486/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0790 - acc: 0.9731 - val_loss: 0.0643 - val_acc: 0.9821\n",
      "Epoch 487/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0611 - acc: 0.9731 - val_loss: 0.0530 - val_acc: 0.9776\n",
      "Epoch 488/800\n",
      "223/223 [==============================] - 0s 117us/step - loss: 0.0681 - acc: 0.9731 - val_loss: 0.0468 - val_acc: 0.9865\n",
      "Epoch 489/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0680 - acc: 0.9686 - val_loss: 0.0584 - val_acc: 0.9776\n",
      "Epoch 490/800\n",
      "223/223 [==============================] - 0s 139us/step - loss: 0.0676 - acc: 0.9731 - val_loss: 0.0524 - val_acc: 0.9865\n",
      "Epoch 491/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0700 - acc: 0.9776 - val_loss: 0.0532 - val_acc: 0.9910\n",
      "Epoch 492/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0571 - acc: 0.9865 - val_loss: 0.0492 - val_acc: 0.9865\n",
      "Epoch 493/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0513 - acc: 0.9821 - val_loss: 0.0443 - val_acc: 0.9821\n",
      "Epoch 494/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0438 - acc: 0.9865 - val_loss: 0.0408 - val_acc: 0.9865\n",
      "Epoch 495/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0480 - acc: 0.9821 - val_loss: 0.0455 - val_acc: 0.9910\n",
      "Epoch 496/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0545 - acc: 0.9865 - val_loss: 0.0399 - val_acc: 0.9865\n",
      "Epoch 497/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0466 - acc: 0.9821 - val_loss: 0.0421 - val_acc: 0.9910\n",
      "Epoch 498/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0412 - acc: 0.9865 - val_loss: 0.0388 - val_acc: 0.9821\n",
      "Epoch 499/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0433 - acc: 0.9865 - val_loss: 0.0371 - val_acc: 0.9865\n",
      "Epoch 500/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0390 - acc: 0.9865 - val_loss: 0.0376 - val_acc: 0.9865\n",
      "Epoch 501/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0395 - acc: 0.9865 - val_loss: 0.0397 - val_acc: 0.9910\n",
      "Epoch 502/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0393 - acc: 0.9910 - val_loss: 0.0365 - val_acc: 0.9865\n",
      "Epoch 503/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0392 - acc: 0.9865 - val_loss: 0.0361 - val_acc: 0.9910\n",
      "Epoch 504/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0381 - acc: 0.9821 - val_loss: 0.0371 - val_acc: 0.9865\n",
      "Epoch 505/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0448 - acc: 0.9865 - val_loss: 0.0349 - val_acc: 0.9910\n",
      "Epoch 506/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0437 - acc: 0.9865 - val_loss: 0.0379 - val_acc: 0.9865\n",
      "Epoch 507/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0464 - acc: 0.9865 - val_loss: 0.0367 - val_acc: 0.9910\n",
      "Epoch 508/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0429 - acc: 0.9865 - val_loss: 0.0400 - val_acc: 0.9865\n",
      "Epoch 509/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0582 - acc: 0.9821 - val_loss: 0.0391 - val_acc: 0.9910\n",
      "Epoch 510/800\n",
      "223/223 [==============================] - 0s 141us/step - loss: 0.0466 - acc: 0.9910 - val_loss: 0.0395 - val_acc: 0.9865\n",
      "Epoch 511/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0403 - acc: 0.9865 - val_loss: 0.0465 - val_acc: 0.9910\n",
      "Epoch 512/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0471 - acc: 0.9910 - val_loss: 0.0384 - val_acc: 0.9865\n",
      "Epoch 513/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0387 - acc: 0.9910 - val_loss: 0.0381 - val_acc: 0.9865\n",
      "Epoch 514/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0447 - acc: 0.9821 - val_loss: 0.0517 - val_acc: 0.9821\n",
      "Epoch 515/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0665 - acc: 0.9776 - val_loss: 0.1219 - val_acc: 0.9552\n",
      "Epoch 516/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1594 - acc: 0.9372 - val_loss: 0.1230 - val_acc: 0.9417\n",
      "Epoch 517/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.1223 - acc: 0.9462 - val_loss: 0.1371 - val_acc: 0.9372\n",
      "Epoch 518/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.0954 - acc: 0.9552 - val_loss: 0.0535 - val_acc: 0.9865\n",
      "Epoch 519/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0686 - acc: 0.9821 - val_loss: 0.0697 - val_acc: 0.9686\n",
      "Epoch 520/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0699 - acc: 0.9731 - val_loss: 0.0925 - val_acc: 0.9507\n",
      "Epoch 521/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0788 - acc: 0.9641 - val_loss: 0.0422 - val_acc: 0.9910\n",
      "Epoch 522/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0438 - acc: 0.9865 - val_loss: 0.0439 - val_acc: 0.9910\n",
      "Epoch 523/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0469 - acc: 0.9821 - val_loss: 0.0415 - val_acc: 0.9865\n",
      "Epoch 524/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0464 - acc: 0.9821 - val_loss: 0.0393 - val_acc: 0.9865\n",
      "Epoch 525/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0388 - acc: 0.9910 - val_loss: 0.0396 - val_acc: 0.9865\n",
      "Epoch 526/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0393 - acc: 0.9910 - val_loss: 0.0370 - val_acc: 0.9910\n",
      "Epoch 527/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0399 - acc: 0.9910 - val_loss: 0.0378 - val_acc: 0.9865\n",
      "Epoch 528/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0417 - acc: 0.9865 - val_loss: 0.0468 - val_acc: 0.9910\n",
      "Epoch 529/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0482 - acc: 0.9865 - val_loss: 0.0452 - val_acc: 0.9910\n",
      "Epoch 530/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0453 - acc: 0.9821 - val_loss: 0.0376 - val_acc: 0.9910\n",
      "Epoch 531/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0724 - acc: 0.9641 - val_loss: 0.0443 - val_acc: 0.9865\n",
      "Epoch 532/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0688 - acc: 0.9641 - val_loss: 0.0591 - val_acc: 0.9821\n",
      "Epoch 533/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0925 - acc: 0.9552 - val_loss: 0.0447 - val_acc: 0.9865\n",
      "Epoch 534/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0688 - acc: 0.9596 - val_loss: 0.0572 - val_acc: 0.9821\n",
      "Epoch 535/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0491 - acc: 0.9865 - val_loss: 0.0545 - val_acc: 0.9821\n",
      "Epoch 536/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0707 - acc: 0.9686 - val_loss: 0.0371 - val_acc: 0.9821\n",
      "Epoch 537/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0447 - acc: 0.9865 - val_loss: 0.0343 - val_acc: 0.9910\n",
      "Epoch 538/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0390 - acc: 0.9910 - val_loss: 0.0315 - val_acc: 0.9910\n",
      "Epoch 539/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0358 - acc: 0.9910 - val_loss: 0.0317 - val_acc: 0.9910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 540/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0346 - acc: 0.9865 - val_loss: 0.0336 - val_acc: 0.9955\n",
      "Epoch 541/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0329 - acc: 0.9955 - val_loss: 0.0341 - val_acc: 0.9955\n",
      "Epoch 542/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0370 - acc: 0.9865 - val_loss: 0.0299 - val_acc: 0.9865\n",
      "Epoch 543/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0321 - acc: 0.9865 - val_loss: 0.0309 - val_acc: 0.9910\n",
      "Epoch 544/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.0346 - acc: 0.9865 - val_loss: 0.0313 - val_acc: 0.9910\n",
      "Epoch 545/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0321 - acc: 0.9955 - val_loss: 0.0307 - val_acc: 0.9910\n",
      "Epoch 546/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0326 - acc: 0.9910 - val_loss: 0.0289 - val_acc: 0.9865\n",
      "Epoch 547/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0313 - acc: 0.9865 - val_loss: 0.0289 - val_acc: 0.9910\n",
      "Epoch 548/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0312 - acc: 0.9865 - val_loss: 0.0291 - val_acc: 0.9910\n",
      "Epoch 549/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0313 - acc: 0.9910 - val_loss: 0.0281 - val_acc: 0.9910\n",
      "Epoch 550/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0324 - acc: 0.9910 - val_loss: 0.0286 - val_acc: 0.9910\n",
      "Epoch 551/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0340 - acc: 0.9865 - val_loss: 0.0319 - val_acc: 0.9865\n",
      "Epoch 552/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0326 - acc: 0.9910 - val_loss: 0.0380 - val_acc: 0.9910\n",
      "Epoch 553/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0401 - acc: 0.9865 - val_loss: 0.0300 - val_acc: 0.9910\n",
      "Epoch 554/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0362 - acc: 0.9865 - val_loss: 0.0293 - val_acc: 0.9910\n",
      "Epoch 555/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0389 - acc: 0.9821 - val_loss: 0.0283 - val_acc: 0.9955\n",
      "Epoch 556/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.0309 - acc: 0.9910 - val_loss: 0.0273 - val_acc: 0.9955\n",
      "Epoch 557/800\n",
      "223/223 [==============================] - 0s 146us/step - loss: 0.0296 - acc: 0.9955 - val_loss: 0.0273 - val_acc: 0.9955\n",
      "Epoch 558/800\n",
      "223/223 [==============================] - 0s 139us/step - loss: 0.0299 - acc: 0.9955 - val_loss: 0.0316 - val_acc: 0.9910\n",
      "Epoch 559/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0334 - acc: 0.9910 - val_loss: 0.0328 - val_acc: 0.9865\n",
      "Epoch 560/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0312 - acc: 0.9865 - val_loss: 0.0258 - val_acc: 0.9910\n",
      "Epoch 561/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0283 - acc: 0.9955 - val_loss: 0.0257 - val_acc: 0.9910\n",
      "Epoch 562/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0269 - acc: 0.9910 - val_loss: 0.0277 - val_acc: 0.9910\n",
      "Epoch 563/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0330 - acc: 0.9910 - val_loss: 0.0304 - val_acc: 0.9865\n",
      "Epoch 564/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0362 - acc: 0.9865 - val_loss: 0.0337 - val_acc: 0.9910\n",
      "Epoch 565/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0454 - acc: 0.9910 - val_loss: 0.0305 - val_acc: 0.9865\n",
      "Epoch 566/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0470 - acc: 0.9865 - val_loss: 0.0533 - val_acc: 0.9865\n",
      "Epoch 567/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0545 - acc: 0.9865 - val_loss: 0.0456 - val_acc: 0.9821\n",
      "Epoch 568/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0443 - acc: 0.9776 - val_loss: 0.0618 - val_acc: 0.9821\n",
      "Epoch 569/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0459 - acc: 0.9821 - val_loss: 0.0358 - val_acc: 0.9910\n",
      "Epoch 570/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0307 - acc: 0.9910 - val_loss: 0.0269 - val_acc: 0.9910\n",
      "Epoch 571/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0276 - acc: 0.9910 - val_loss: 0.0263 - val_acc: 0.9955\n",
      "Epoch 572/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0263 - acc: 0.9910 - val_loss: 0.0255 - val_acc: 0.9910\n",
      "Epoch 573/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0257 - acc: 0.9910 - val_loss: 0.0244 - val_acc: 0.9955\n",
      "Epoch 574/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0310 - acc: 0.9865 - val_loss: 0.0324 - val_acc: 0.9910\n",
      "Epoch 575/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0406 - acc: 0.9821 - val_loss: 0.0567 - val_acc: 0.9731\n",
      "Epoch 576/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0681 - acc: 0.9731 - val_loss: 0.0429 - val_acc: 0.9821\n",
      "Epoch 577/800\n",
      "223/223 [==============================] - 0s 146us/step - loss: 0.0562 - acc: 0.9821 - val_loss: 0.0325 - val_acc: 0.9910\n",
      "Epoch 578/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0799 - acc: 0.9686 - val_loss: 0.0436 - val_acc: 0.9865\n",
      "Epoch 579/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0742 - acc: 0.9641 - val_loss: 0.0470 - val_acc: 0.9731\n",
      "Epoch 580/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0771 - acc: 0.9731 - val_loss: 0.0447 - val_acc: 0.9865\n",
      "Epoch 581/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0488 - acc: 0.9910 - val_loss: 0.0570 - val_acc: 0.9776\n",
      "Epoch 582/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0827 - acc: 0.9686 - val_loss: 0.0810 - val_acc: 0.9686\n",
      "Epoch 583/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.3259 - acc: 0.8924 - val_loss: 0.3256 - val_acc: 0.8565\n",
      "Epoch 584/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.6600 - acc: 0.8341 - val_loss: 0.1390 - val_acc: 0.9327\n",
      "Epoch 585/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.4316 - acc: 0.8610 - val_loss: 0.5480 - val_acc: 0.8161\n",
      "Epoch 586/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.3552 - acc: 0.8610 - val_loss: 0.1325 - val_acc: 0.9507\n",
      "Epoch 587/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.1835 - acc: 0.9283 - val_loss: 0.2379 - val_acc: 0.9013\n",
      "Epoch 588/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.2672 - acc: 0.9148 - val_loss: 0.4091 - val_acc: 0.8655\n",
      "Epoch 589/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.2056 - acc: 0.9327 - val_loss: 0.1317 - val_acc: 0.9507\n",
      "Epoch 590/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1388 - acc: 0.9417 - val_loss: 0.0716 - val_acc: 0.9731\n",
      "Epoch 591/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.1074 - acc: 0.9552 - val_loss: 0.0787 - val_acc: 0.9596\n",
      "Epoch 592/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0907 - acc: 0.9552 - val_loss: 0.0557 - val_acc: 0.9821\n",
      "Epoch 593/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0710 - acc: 0.9776 - val_loss: 0.0655 - val_acc: 0.9776\n",
      "Epoch 594/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0576 - acc: 0.9865 - val_loss: 0.0504 - val_acc: 0.9865\n",
      "Epoch 595/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0542 - acc: 0.9910 - val_loss: 0.0445 - val_acc: 0.9865\n",
      "Epoch 596/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0491 - acc: 0.9731 - val_loss: 0.0389 - val_acc: 0.9910\n",
      "Epoch 597/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0463 - acc: 0.9865 - val_loss: 0.0379 - val_acc: 0.9865\n",
      "Epoch 598/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0375 - acc: 0.9910 - val_loss: 0.0340 - val_acc: 0.9955\n",
      "Epoch 599/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0345 - acc: 0.9910 - val_loss: 0.0317 - val_acc: 0.9955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0323 - acc: 0.9955 - val_loss: 0.0305 - val_acc: 0.9955\n",
      "Epoch 601/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0323 - acc: 0.9865 - val_loss: 0.0299 - val_acc: 0.9955\n",
      "Epoch 602/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0348 - acc: 0.9910 - val_loss: 0.0294 - val_acc: 0.9955\n",
      "Epoch 603/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0406 - acc: 0.9865 - val_loss: 0.0345 - val_acc: 0.9910\n",
      "Epoch 604/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0374 - acc: 0.9865 - val_loss: 0.0298 - val_acc: 0.9910\n",
      "Epoch 605/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0302 - acc: 0.9865 - val_loss: 0.0283 - val_acc: 0.9910\n",
      "Epoch 606/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0303 - acc: 0.9865 - val_loss: 0.0284 - val_acc: 0.9955\n",
      "Epoch 607/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0308 - acc: 0.9910 - val_loss: 0.0293 - val_acc: 0.9865\n",
      "Epoch 608/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0306 - acc: 0.9865 - val_loss: 0.0269 - val_acc: 0.9955\n",
      "Epoch 609/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0284 - acc: 0.9910 - val_loss: 0.0265 - val_acc: 0.9955\n",
      "Epoch 610/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0280 - acc: 0.9910 - val_loss: 0.0264 - val_acc: 0.9955\n",
      "Epoch 611/800\n",
      "223/223 [==============================] - 0s 143us/step - loss: 0.0316 - acc: 0.9865 - val_loss: 0.0269 - val_acc: 0.9910\n",
      "Epoch 612/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0298 - acc: 0.9955 - val_loss: 0.0264 - val_acc: 0.9955\n",
      "Epoch 613/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0302 - acc: 0.9865 - val_loss: 0.0259 - val_acc: 0.9955\n",
      "Epoch 614/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0312 - acc: 0.9910 - val_loss: 0.0256 - val_acc: 0.9955\n",
      "Epoch 615/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0297 - acc: 0.9910 - val_loss: 0.0253 - val_acc: 0.9955\n",
      "Epoch 616/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0270 - acc: 0.9955 - val_loss: 0.0256 - val_acc: 0.9955\n",
      "Epoch 617/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0272 - acc: 0.9910 - val_loss: 0.0253 - val_acc: 0.9955\n",
      "Epoch 618/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0258 - acc: 0.9955 - val_loss: 0.0266 - val_acc: 0.9910\n",
      "Epoch 619/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0260 - acc: 0.9955 - val_loss: 0.0262 - val_acc: 0.9910\n",
      "Epoch 620/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0278 - acc: 0.9910 - val_loss: 0.0275 - val_acc: 0.9955\n",
      "Epoch 621/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0287 - acc: 0.9910 - val_loss: 0.0248 - val_acc: 0.9955\n",
      "Epoch 622/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0254 - acc: 0.9910 - val_loss: 0.0240 - val_acc: 0.9955\n",
      "Epoch 623/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0296 - acc: 0.9910 - val_loss: 0.0239 - val_acc: 0.9955\n",
      "Epoch 624/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0263 - acc: 0.9865 - val_loss: 0.0240 - val_acc: 0.9955\n",
      "Epoch 625/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0267 - acc: 0.9910 - val_loss: 0.0234 - val_acc: 0.9955\n",
      "Epoch 626/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0264 - acc: 0.9910 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 627/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 0.9910\n",
      "Epoch 628/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0277 - acc: 0.9910 - val_loss: 0.0226 - val_acc: 0.9955\n",
      "Epoch 629/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0295 - acc: 0.9910 - val_loss: 0.0233 - val_acc: 0.9955\n",
      "Epoch 630/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0298 - acc: 0.9865 - val_loss: 0.0245 - val_acc: 0.9910\n",
      "Epoch 631/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0378 - acc: 0.9910 - val_loss: 0.0227 - val_acc: 0.9955\n",
      "Epoch 632/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0334 - acc: 0.9910 - val_loss: 0.0264 - val_acc: 0.9910\n",
      "Epoch 633/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0338 - acc: 0.9910 - val_loss: 0.0234 - val_acc: 0.9955\n",
      "Epoch 634/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0270 - acc: 0.9955 - val_loss: 0.0238 - val_acc: 1.0000\n",
      "Epoch 635/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0262 - acc: 0.9865 - val_loss: 0.0224 - val_acc: 0.9955\n",
      "Epoch 636/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0244 - acc: 0.9910 - val_loss: 0.0225 - val_acc: 0.9910\n",
      "Epoch 637/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0298 - acc: 0.9821 - val_loss: 0.0229 - val_acc: 0.9955\n",
      "Epoch 638/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0222 - acc: 0.9955 - val_loss: 0.0224 - val_acc: 0.9955\n",
      "Epoch 639/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0243 - acc: 0.9910 - val_loss: 0.0215 - val_acc: 0.9955\n",
      "Epoch 640/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0233 - acc: 0.9910 - val_loss: 0.0220 - val_acc: 0.9955\n",
      "Epoch 641/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0235 - acc: 0.9910 - val_loss: 0.0213 - val_acc: 0.9955\n",
      "Epoch 642/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0238 - acc: 0.9955 - val_loss: 0.0209 - val_acc: 0.9955\n",
      "Epoch 643/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0259 - acc: 0.9910 - val_loss: 0.0208 - val_acc: 0.9955\n",
      "Epoch 644/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0238 - acc: 0.9955 - val_loss: 0.0248 - val_acc: 0.9955\n",
      "Epoch 645/800\n",
      "223/223 [==============================] - 0s 148us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.0232 - val_acc: 1.0000\n",
      "Epoch 646/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0235 - acc: 0.9910 - val_loss: 0.0203 - val_acc: 0.9955\n",
      "Epoch 647/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0263 - acc: 0.9910 - val_loss: 0.0204 - val_acc: 0.9955\n",
      "Epoch 648/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0249 - acc: 0.9865 - val_loss: 0.0236 - val_acc: 0.9955\n",
      "Epoch 649/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0249 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9955\n",
      "Epoch 650/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0237 - acc: 0.9955 - val_loss: 0.0243 - val_acc: 0.9910\n",
      "Epoch 651/800\n",
      "223/223 [==============================] - 0s 117us/step - loss: 0.0268 - acc: 0.9865 - val_loss: 0.0231 - val_acc: 0.9910\n",
      "Epoch 652/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0224 - acc: 0.9955 - val_loss: 0.0252 - val_acc: 0.9910\n",
      "Epoch 653/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0278 - acc: 0.9910 - val_loss: 0.0243 - val_acc: 0.9955\n",
      "Epoch 654/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0307 - acc: 0.9910 - val_loss: 0.0222 - val_acc: 0.9955\n",
      "Epoch 655/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0240 - acc: 0.9910 - val_loss: 0.0228 - val_acc: 0.9910\n",
      "Epoch 656/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0224 - acc: 0.9910 - val_loss: 0.0245 - val_acc: 0.9910\n",
      "Epoch 657/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0235 - acc: 0.9955 - val_loss: 0.0199 - val_acc: 0.9955\n",
      "Epoch 658/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0255 - acc: 0.9910 - val_loss: 0.0196 - val_acc: 0.9955\n",
      "Epoch 659/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 0.0203 - val_acc: 0.9955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 660/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0252 - acc: 0.9910 - val_loss: 0.0215 - val_acc: 0.9910\n",
      "Epoch 661/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0301 - acc: 0.9910 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 662/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0259 - val_acc: 0.9910\n",
      "Epoch 663/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0279 - acc: 0.9910 - val_loss: 0.0198 - val_acc: 1.0000\n",
      "Epoch 664/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0211 - acc: 0.9910 - val_loss: 0.0190 - val_acc: 0.9955\n",
      "Epoch 665/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0198 - acc: 0.9955 - val_loss: 0.0188 - val_acc: 0.9955\n",
      "Epoch 666/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0223 - acc: 0.9865 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 667/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0222 - acc: 0.9955 - val_loss: 0.0187 - val_acc: 0.9955\n",
      "Epoch 668/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0197 - acc: 0.9955 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 669/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0208 - acc: 0.9955 - val_loss: 0.0184 - val_acc: 0.9955\n",
      "Epoch 670/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0260 - acc: 0.9910 - val_loss: 0.0224 - val_acc: 0.9955\n",
      "Epoch 671/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0230 - acc: 0.9955 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 672/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0231 - acc: 0.9910 - val_loss: 0.0189 - val_acc: 0.9955\n",
      "Epoch 673/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.0221 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9955\n",
      "Epoch 674/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.0219 - acc: 0.9910 - val_loss: 0.0184 - val_acc: 0.9955\n",
      "Epoch 675/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0215 - acc: 0.9955 - val_loss: 0.0188 - val_acc: 1.0000\n",
      "Epoch 676/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0213 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9955\n",
      "Epoch 677/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0231 - acc: 0.9955 - val_loss: 0.0204 - val_acc: 1.0000\n",
      "Epoch 678/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0228 - acc: 1.0000 - val_loss: 0.0230 - val_acc: 0.9955\n",
      "Epoch 679/800\n",
      "223/223 [==============================] - 0s 146us/step - loss: 0.0262 - acc: 0.9910 - val_loss: 0.0178 - val_acc: 0.9955\n",
      "Epoch 680/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 0.0170 - val_acc: 1.0000\n",
      "Epoch 681/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0198 - acc: 0.9955 - val_loss: 0.0172 - val_acc: 0.9955\n",
      "Epoch 682/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0195 - acc: 0.9955 - val_loss: 0.0173 - val_acc: 0.9955\n",
      "Epoch 683/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0205 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "Epoch 684/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0241 - acc: 0.9955 - val_loss: 0.0195 - val_acc: 0.9955\n",
      "Epoch 685/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0242 - acc: 0.9910 - val_loss: 0.0214 - val_acc: 0.9955\n",
      "Epoch 686/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0285 - acc: 0.9955 - val_loss: 0.0193 - val_acc: 0.9955\n",
      "Epoch 687/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0235 - acc: 0.9910 - val_loss: 0.0220 - val_acc: 0.9955\n",
      "Epoch 688/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0221 - acc: 0.9955 - val_loss: 0.0238 - val_acc: 0.9955\n",
      "Epoch 689/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0239 - acc: 0.9955 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 690/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0253 - acc: 0.9955 - val_loss: 0.0180 - val_acc: 0.9955\n",
      "Epoch 691/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0209 - acc: 0.9955 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 692/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0195 - acc: 0.9955 - val_loss: 0.0165 - val_acc: 0.9955\n",
      "Epoch 693/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0186 - acc: 0.9910 - val_loss: 0.0161 - val_acc: 0.9955\n",
      "Epoch 694/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.0168 - acc: 0.9955 - val_loss: 0.0173 - val_acc: 1.0000\n",
      "Epoch 695/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0179 - acc: 0.9955 - val_loss: 0.0155 - val_acc: 0.9955\n",
      "Epoch 696/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0165 - acc: 0.9955 - val_loss: 0.0152 - val_acc: 1.0000\n",
      "Epoch 697/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0186 - acc: 1.0000 - val_loss: 0.0151 - val_acc: 1.0000\n",
      "Epoch 698/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0198 - acc: 0.9910 - val_loss: 0.0181 - val_acc: 0.9910\n",
      "Epoch 699/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0183 - acc: 0.9910 - val_loss: 0.0158 - val_acc: 1.0000\n",
      "Epoch 700/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 0.0154 - val_acc: 1.0000\n",
      "Epoch 701/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0161 - acc: 1.0000 - val_loss: 0.0156 - val_acc: 0.9955\n",
      "Epoch 702/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0159 - acc: 0.9955 - val_loss: 0.0146 - val_acc: 0.9955\n",
      "Epoch 703/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 1.0000\n",
      "Epoch 704/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0213 - acc: 0.9955 - val_loss: 0.0177 - val_acc: 0.9910\n",
      "Epoch 705/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0253 - acc: 0.9910 - val_loss: 0.0181 - val_acc: 1.0000\n",
      "Epoch 706/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0302 - acc: 0.9910 - val_loss: 0.0183 - val_acc: 0.9955\n",
      "Epoch 707/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0182 - acc: 1.0000 - val_loss: 0.0191 - val_acc: 1.0000\n",
      "Epoch 708/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0220 - acc: 0.9955 - val_loss: 0.0204 - val_acc: 0.9955\n",
      "Epoch 709/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0365 - acc: 0.9865 - val_loss: 0.0338 - val_acc: 0.9955\n",
      "Epoch 710/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0475 - acc: 0.9776 - val_loss: 0.0184 - val_acc: 1.0000\n",
      "Epoch 711/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0603 - acc: 0.9686 - val_loss: 0.1155 - val_acc: 0.9372\n",
      "Epoch 712/800\n",
      "223/223 [==============================] - 0s 139us/step - loss: 0.0811 - acc: 0.9596 - val_loss: 0.0769 - val_acc: 0.9641\n",
      "Epoch 713/800\n",
      "223/223 [==============================] - 0s 173us/step - loss: 0.0892 - acc: 0.9731 - val_loss: 0.0865 - val_acc: 0.9641\n",
      "Epoch 714/800\n",
      "223/223 [==============================] - 0s 157us/step - loss: 0.0834 - acc: 0.9641 - val_loss: 0.0640 - val_acc: 0.9731\n",
      "Epoch 715/800\n",
      "223/223 [==============================] - 0s 166us/step - loss: 0.1567 - acc: 0.9596 - val_loss: 0.0314 - val_acc: 0.9865\n",
      "Epoch 716/800\n",
      "223/223 [==============================] - 0s 148us/step - loss: 0.1595 - acc: 0.9417 - val_loss: 0.3602 - val_acc: 0.8879\n",
      "Epoch 717/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.2267 - acc: 0.9238 - val_loss: 0.6227 - val_acc: 0.8834\n",
      "Epoch 718/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.3237 - acc: 0.8969 - val_loss: 0.1934 - val_acc: 0.9238\n",
      "Epoch 719/800\n",
      "223/223 [==============================] - 0s 155us/step - loss: 0.1879 - acc: 0.9327 - val_loss: 0.2362 - val_acc: 0.9283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 720/800\n",
      "223/223 [==============================] - 0s 150us/step - loss: 0.2588 - acc: 0.9013 - val_loss: 0.1826 - val_acc: 0.9372\n",
      "Epoch 721/800\n",
      "223/223 [==============================] - 0s 134us/step - loss: 0.3073 - acc: 0.9058 - val_loss: 0.6179 - val_acc: 0.8700\n",
      "Epoch 722/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.4854 - acc: 0.8341 - val_loss: 0.3847 - val_acc: 0.8655\n",
      "Epoch 723/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.6371 - acc: 0.8296 - val_loss: 0.5258 - val_acc: 0.7982\n",
      "Epoch 724/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.5361 - acc: 0.8161 - val_loss: 0.3142 - val_acc: 0.8520\n",
      "Epoch 725/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.3795 - acc: 0.8520 - val_loss: 0.3712 - val_acc: 0.8834\n",
      "Epoch 726/800\n",
      "223/223 [==============================] - 0s 143us/step - loss: 0.3459 - acc: 0.8834 - val_loss: 0.3660 - val_acc: 0.8386\n",
      "Epoch 727/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.3869 - acc: 0.8655 - val_loss: 0.4246 - val_acc: 0.8296\n",
      "Epoch 728/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.2996 - acc: 0.8700 - val_loss: 0.3111 - val_acc: 0.8475\n",
      "Epoch 729/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.3432 - acc: 0.8610 - val_loss: 0.2769 - val_acc: 0.8655\n",
      "Epoch 730/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.2199 - acc: 0.8969 - val_loss: 0.1938 - val_acc: 0.9013\n",
      "Epoch 731/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1886 - acc: 0.8969 - val_loss: 0.1720 - val_acc: 0.9058\n",
      "Epoch 732/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1717 - acc: 0.9148 - val_loss: 0.1623 - val_acc: 0.9283\n",
      "Epoch 733/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.1629 - acc: 0.9327 - val_loss: 0.1509 - val_acc: 0.9327\n",
      "Epoch 734/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1519 - acc: 0.9283 - val_loss: 0.1469 - val_acc: 0.9283\n",
      "Epoch 735/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1480 - acc: 0.9283 - val_loss: 0.1361 - val_acc: 0.9372\n",
      "Epoch 736/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1444 - acc: 0.9238 - val_loss: 0.1415 - val_acc: 0.9283\n",
      "Epoch 737/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1452 - acc: 0.9283 - val_loss: 0.1307 - val_acc: 0.9238\n",
      "Epoch 738/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.1395 - acc: 0.9283 - val_loss: 0.1321 - val_acc: 0.9462\n",
      "Epoch 739/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1273 - acc: 0.9462 - val_loss: 0.1240 - val_acc: 0.9417\n",
      "Epoch 740/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1275 - acc: 0.9417 - val_loss: 0.1176 - val_acc: 0.9372\n",
      "Epoch 741/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1239 - acc: 0.9372 - val_loss: 0.1207 - val_acc: 0.9417\n",
      "Epoch 742/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.1209 - acc: 0.9462 - val_loss: 0.1131 - val_acc: 0.9552\n",
      "Epoch 743/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1161 - acc: 0.9552 - val_loss: 0.1094 - val_acc: 0.9507\n",
      "Epoch 744/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1132 - acc: 0.9596 - val_loss: 0.1096 - val_acc: 0.9507\n",
      "Epoch 745/800\n",
      "223/223 [==============================] - 0s 161us/step - loss: 0.1120 - acc: 0.9552 - val_loss: 0.1045 - val_acc: 0.9552\n",
      "Epoch 746/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1120 - acc: 0.9507 - val_loss: 0.1037 - val_acc: 0.9596\n",
      "Epoch 747/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.1070 - acc: 0.9507 - val_loss: 0.1022 - val_acc: 0.9596\n",
      "Epoch 748/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.1029 - acc: 0.9596 - val_loss: 0.1008 - val_acc: 0.9552\n",
      "Epoch 749/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1044 - acc: 0.9507 - val_loss: 0.0973 - val_acc: 0.9552\n",
      "Epoch 750/800\n",
      "223/223 [==============================] - 0s 139us/step - loss: 0.1026 - acc: 0.9552 - val_loss: 0.1025 - val_acc: 0.9596\n",
      "Epoch 751/800\n",
      "223/223 [==============================] - 0s 135us/step - loss: 0.1021 - acc: 0.9641 - val_loss: 0.0969 - val_acc: 0.9596\n",
      "Epoch 752/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0990 - acc: 0.9596 - val_loss: 0.0973 - val_acc: 0.9596\n",
      "Epoch 753/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0959 - acc: 0.9686 - val_loss: 0.0939 - val_acc: 0.9596\n",
      "Epoch 754/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.1022 - acc: 0.9552 - val_loss: 0.0910 - val_acc: 0.9596\n",
      "Epoch 755/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1058 - acc: 0.9596 - val_loss: 0.0949 - val_acc: 0.9641\n",
      "Epoch 756/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0973 - acc: 0.9686 - val_loss: 0.0954 - val_acc: 0.9641\n",
      "Epoch 757/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0946 - acc: 0.9596 - val_loss: 0.0849 - val_acc: 0.9731\n",
      "Epoch 758/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0878 - acc: 0.9731 - val_loss: 0.0820 - val_acc: 0.9731\n",
      "Epoch 759/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0894 - acc: 0.9686 - val_loss: 0.0873 - val_acc: 0.9686\n",
      "Epoch 760/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0935 - acc: 0.9686 - val_loss: 0.0786 - val_acc: 0.9821\n",
      "Epoch 761/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0791 - acc: 0.9686 - val_loss: 0.0771 - val_acc: 0.9776\n",
      "Epoch 762/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0926 - acc: 0.9686 - val_loss: 0.0753 - val_acc: 0.9731\n",
      "Epoch 763/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0808 - acc: 0.9641 - val_loss: 0.0731 - val_acc: 0.9731\n",
      "Epoch 764/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0819 - acc: 0.9865 - val_loss: 0.0738 - val_acc: 0.9821\n",
      "Epoch 765/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0855 - acc: 0.9686 - val_loss: 0.0842 - val_acc: 0.9776\n",
      "Epoch 766/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0861 - acc: 0.9686 - val_loss: 0.0730 - val_acc: 0.9776\n",
      "Epoch 767/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0775 - acc: 0.9731 - val_loss: 0.0695 - val_acc: 0.9731\n",
      "Epoch 768/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0722 - acc: 0.9731 - val_loss: 0.0674 - val_acc: 0.9821\n",
      "Epoch 769/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0766 - acc: 0.9686 - val_loss: 0.0672 - val_acc: 0.9776\n",
      "Epoch 770/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0677 - acc: 0.9821 - val_loss: 0.0647 - val_acc: 0.9865\n",
      "Epoch 771/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0691 - acc: 0.9821 - val_loss: 0.0640 - val_acc: 0.9865\n",
      "Epoch 772/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0719 - acc: 0.9776 - val_loss: 0.0610 - val_acc: 0.9776\n",
      "Epoch 773/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0691 - acc: 0.9731 - val_loss: 0.0603 - val_acc: 0.9821\n",
      "Epoch 774/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0698 - acc: 0.9821 - val_loss: 0.0656 - val_acc: 0.9776\n",
      "Epoch 775/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0656 - acc: 0.9686 - val_loss: 0.0598 - val_acc: 0.9821\n",
      "Epoch 776/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0641 - acc: 0.9776 - val_loss: 0.0547 - val_acc: 0.9865\n",
      "Epoch 777/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0581 - acc: 0.9865 - val_loss: 0.0537 - val_acc: 0.9865\n",
      "Epoch 778/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0584 - acc: 0.9821 - val_loss: 0.0532 - val_acc: 0.9865\n",
      "Epoch 779/800\n",
      "223/223 [==============================] - 0s 148us/step - loss: 0.0613 - acc: 0.9731 - val_loss: 0.0547 - val_acc: 0.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 780/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0609 - acc: 0.9776 - val_loss: 0.0553 - val_acc: 0.9865\n",
      "Epoch 781/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0616 - acc: 0.9821 - val_loss: 0.0614 - val_acc: 0.9776\n",
      "Epoch 782/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0673 - acc: 0.9686 - val_loss: 0.0592 - val_acc: 0.9821\n",
      "Epoch 783/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0565 - acc: 0.9865 - val_loss: 0.0520 - val_acc: 0.9865\n",
      "Epoch 784/800\n",
      "223/223 [==============================] - 0s 130us/step - loss: 0.0623 - acc: 0.9865 - val_loss: 0.0630 - val_acc: 0.9776\n",
      "Epoch 785/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.0767 - acc: 0.9686 - val_loss: 0.0527 - val_acc: 0.9865\n",
      "Epoch 786/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.0601 - acc: 0.9910 - val_loss: 0.0536 - val_acc: 0.9865\n",
      "Epoch 787/800\n",
      "223/223 [==============================] - 0s 125us/step - loss: 0.0616 - acc: 0.9776 - val_loss: 0.0565 - val_acc: 0.9865\n",
      "Epoch 788/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0773 - acc: 0.9731 - val_loss: 0.0661 - val_acc: 0.9731\n",
      "Epoch 789/800\n",
      "223/223 [==============================] - 0s 132us/step - loss: 0.0863 - acc: 0.9641 - val_loss: 0.0882 - val_acc: 0.9686\n",
      "Epoch 790/800\n",
      "223/223 [==============================] - 0s 137us/step - loss: 0.1041 - acc: 0.9417 - val_loss: 0.0611 - val_acc: 0.9865\n",
      "Epoch 791/800\n",
      "223/223 [==============================] - 0s 141us/step - loss: 0.0753 - acc: 0.9731 - val_loss: 0.0634 - val_acc: 0.9776\n",
      "Epoch 792/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.0677 - acc: 0.9821 - val_loss: 0.0719 - val_acc: 0.9686\n",
      "Epoch 793/800\n",
      "223/223 [==============================] - 0s 148us/step - loss: 0.0571 - acc: 0.9821 - val_loss: 0.0741 - val_acc: 0.9686\n",
      "Epoch 794/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0724 - acc: 0.9731 - val_loss: 0.0569 - val_acc: 0.9821\n",
      "Epoch 795/800\n",
      "223/223 [==============================] - 0s 121us/step - loss: 0.0851 - acc: 0.9596 - val_loss: 0.0506 - val_acc: 0.9821\n",
      "Epoch 796/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.0981 - acc: 0.9686 - val_loss: 0.2577 - val_acc: 0.9013\n",
      "Epoch 797/800\n",
      "223/223 [==============================] - 0s 119us/step - loss: 0.1945 - acc: 0.9372 - val_loss: 0.0743 - val_acc: 0.9776\n",
      "Epoch 798/800\n",
      "223/223 [==============================] - 0s 123us/step - loss: 0.1462 - acc: 0.9283 - val_loss: 0.2096 - val_acc: 0.9013\n",
      "Epoch 799/800\n",
      "223/223 [==============================] - 0s 126us/step - loss: 0.1859 - acc: 0.9283 - val_loss: 0.1338 - val_acc: 0.9417\n",
      "Epoch 800/800\n",
      "223/223 [==============================] - 0s 128us/step - loss: 0.1185 - acc: 0.9552 - val_loss: 0.0930 - val_acc: 0.9641\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs = 800, batch_size=32, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "acc = history_dict['acc']\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.09304386307172177\n",
      "Test accuracy: 0.9641255605381166\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
